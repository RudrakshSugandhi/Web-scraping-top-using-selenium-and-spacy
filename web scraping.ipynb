{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "scrap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2ER7bBKJCf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from selenium import webdriver\n",
        "#from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import requests\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOgJHVKTXsUs",
        "colab_type": "code",
        "outputId": "f9f98db3-e90a-42b9-9b4c-db45ecc40d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "#wd.get(\"https://www.webite-url.com\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Hit:1 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (79.0.3945.79-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: use options instead of chrome_options\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpiMpFCxJCgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://in.linkedin.com/jobs/search?keywords=machine%20learning&location=Pune%2C%20Maharashtra%2C%20India&trk=homepage-jobseeker_jobs-search-bar_search-submit&redirect=false&position=1&pageNum=0&currentJobId=1645890290'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x90FaPzBJCgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#driver = webdriver.Chrome('/content/gdrive/My Drive/colab Notebooks/chromedriver.exe')\n",
        "wd.get(url)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBz_mRERJCgP",
        "colab_type": "code",
        "outputId": "3ffc7fd0-a6d2-4af6-fec4-84501e0bfdf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_element  = wd.find_elements_by_css_selector(\"a[class='result-card__full-card-link']\")\n",
        "print(len(get_element))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAq1gFbNJCgU",
        "colab_type": "code",
        "outputId": "0d237474-f297-4acf-d182-669b4dfb6d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "li =[]\n",
        "for i in range(0,52):\n",
        "    li.append(get_element[i].get_attribute('href'))\n",
        "\n",
        "print(li)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['https://in.linkedin.com/jobs/view/deep-learning-specialist-at-sleepiz-ag-1586344661?refId=b84341df-38d9-4467-b834-1006907df3ca&position=1&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-data-scientist-at-milj%C3%B8rens-1581462219?refId=b84341df-38d9-4467-b834-1006907df3ca&position=2&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-associate-at-cne-systems-1636127364?refId=b84341df-38d9-4467-b834-1006907df3ca&position=3&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-helpshift-1642872899?refId=b84341df-38d9-4467-b834-1006907df3ca&position=4&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-rang-de-1391596009?refId=b84341df-38d9-4467-b834-1006907df3ca&position=5&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-entytle-inc-1616087349?refId=b84341df-38d9-4467-b834-1006907df3ca&position=6&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-aera-technology-1518259120?refId=b84341df-38d9-4467-b834-1006907df3ca&position=7&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/technical-lead-machine-learning-job-at-yash-technologies-1609012504?refId=b84341df-38d9-4467-b834-1006907df3ca&position=8&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-ubs-1654120385?refId=b84341df-38d9-4467-b834-1006907df3ca&position=9&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-machine-learning-7-10-yrs-pune-analytics-data-science-at-maven-workforce-1654370029?refId=b84341df-38d9-4467-b834-1006907df3ca&position=10&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/firstcry-python-developer-deep-learning-computer-vision-4-10-yrs-pune-analytics-data-science-at-firstcry-com-brainbees-solutions-pvt-ltd-1654328828?refId=b84341df-38d9-4467-b834-1006907df3ca&position=11&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/immediate-opening-python-machine-learning-details-are-as-foll-at-alphacom-llc-1561736020?refId=b84341df-38d9-4467-b834-1006907df3ca&position=12&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/deep-learning-architect-ml-solutions-lab-at-amazon-1621104964?refId=b84341df-38d9-4467-b834-1006907df3ca&position=13&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/engineer-data-analytics-%E2%80%93-wireline-services-at-baker-hughes-1657468063?refId=b84341df-38d9-4467-b834-1006907df3ca&position=14&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-with-bigdata-for-4-years-to-6-years-in-pune-at-capgemini-1619360801?refId=b84341df-38d9-4467-b834-1006907df3ca&position=15&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/computer-vision-at-accenture-in-india-1509189111?refId=b84341df-38d9-4467-b834-1006907df3ca&position=16&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/earlysalary-com-manager-senior-manager-marketing-analytics-marketing-customer-analytics-team-3-6-yrs-pune-at-earlysalary-instant-salary-advance-for-employees-1655788313?refId=b84341df-38d9-4467-b834-1006907df3ca&position=17&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/ai-engineer-at-edubrite-systems-inc-1634142267?refId=b84341df-38d9-4467-b834-1006907df3ca&position=18&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/head-of-product-development-at-marketsandmarkets%E2%84%A2-1659879492?refId=b84341df-38d9-4467-b834-1006907df3ca&position=19&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/technology-support-operations-specialist-at-fico-1645119286?refId=b84341df-38d9-4467-b834-1006907df3ca&position=20&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-pune-at-sg-analytics-1538403674?refId=b84341df-38d9-4467-b834-1006907df3ca&position=21&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/intern-threat-research-at-crowdstrike-1655049463?refId=b84341df-38d9-4467-b834-1006907df3ca&position=22&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-tata-communications-transformation-services-tcts-1600953922?refId=b84341df-38d9-4467-b834-1006907df3ca&position=23&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-science-trainer-urgent-at-blend-infotech-india-1635895816?refId=b84341df-38d9-4467-b834-1006907df3ca&position=24&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/solution-cognitive-architect-nlp-machine-learning-12-15-yrs-pune-analytics-data-science-at-insignia-solutions-1628008794?refId=b84341df-38d9-4467-b834-1006907df3ca&position=25&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click', 'https://in.linkedin.com/in/rahul-a-vaidya?trk=guest_job_details_profile-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/business-analyst-at-springer-nature-1650830292?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/business-analyst-at-synechron-1645255466?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-cerebulb-1646863814?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-anheuser-busch-inbev-1639937643?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-customer-loyalty-retention-hiring-for-product-company-at-hackertrail-1645869195?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-happy-financial-services-1609517282?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-engineer-at-eaton-1648707853?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/nlp-data-scientist-at-eli-lilly-and-company-1612214798?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-trianz-1644561328?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/content-analyst-at-sprinklr-1637776619?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-ola-ani-technologies-pvt-ltd-1619996681?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/associate-product-data-analyst-at-eaton-1649665698?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-expedia-group-1619928622?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/big-data-engineer-python-and-spark-must-skills-hiring-for-product-company-at-hackertrail-1645867421?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/sr-data-scientist-at-common-1645219422?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-aera-technology-1518259120?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/technology-intern-digital-payments-domain-at-national-payments-corporation-of-india-npci-1625370391?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-analyst-at-myntra-jabong-1596049820?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-cure-fit-1599298045?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-at-sg-analytics-1609093407?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/intern-at-cloud-counselage-pvt-ltd-1609520691?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/intern-at-cloud-counselage-pvt-ltd-1609523055?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/ai-scientist-opportunity-at-wipro-limited-1644463620?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-scientist-machine-learning-at-accenture-1616514251?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/machine-learning-artifical-intelligence-engineer-76096-at-amd-1543790184?trk=guest_job_details_job-result-card_result-card_full-click', 'https://in.linkedin.com/jobs/view/data-science-expert-nlp-at-talentica-software-1619957816?trk=guest_job_details_job-result-card_result-card_full-click']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9a9msQ2BJCgZ",
        "colab_type": "code",
        "outputId": "d8a84be6-37b6-4009-808f-0b07c3807bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "import time\n",
        "li1=[]\n",
        "for i in range(0,20):\n",
        "    url = li[i]\n",
        "    \n",
        "    wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "    #window_before = driver.window_handles[0]\n",
        "   # time.sleep(3)\n",
        "    wd.get(url)\n",
        "   # window_after = driver.window_handles[1]\n",
        "    ele =  wd.find_elements_by_css_selector(\"div[class = 'description__text description__text--rich']\")\n",
        "    for users in  ele:\n",
        "        li1.append(users.text)\n",
        "    wd.close()    \n",
        "\n",
        "\n",
        "    \n",
        "print(li1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[\"Responsibilities\\nImplementation of advanced deep learning algorithms for sleep stage classification.\\nDevelopment of advanced models with the combination of CNN and RNN.\\nDeveloping advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner.\\nImplementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information.\\nCollaborating with clients and other stakeholders to effectively integrate and communicate analysis findings.\\nMentoring and providing project management support to the Associates on the team.\\nEvaluating emerging data-sets and technologies that may contribute to our existing analytical platforms.\\nEstablish the scope of the project, lead internal communication with stakeholders, and ensure delivery of the project per commitment.\\nContributing to the thought leadership of the company by helping in researching the evolving topics and publishing them.\\n\\nRequirements\\nMin 6 years of work experience in data analysis.\\nStrong knowledge in deep learning and artificial intelligence (min. 5 years'experience).\\nHaving hands-on experience on advanced analytics concepts and algorithms (e.g. Regression analysis Logistic Regression/Decision Tree, Time series analysis, Support Vector Machine, Neural Network etc.).\\nProficient in Python language (Tensor Flow and Keras).\\nStrong knowledge of statistics.\\nGood knowledge of project management software.\", 'Machine Learning/ Data Scientist\\n\\nJob Requirements\\nMinimum two years of experience with Machine Learning technologies\\nExpert in building custom ML algorithms leveraging statistical concepts and ML tools\\nApply machine learning, data mining, predictive modelling & statistical techniques to create new scalable models.\\nUnderstanding & working knowledge in Natural Language Processing & Conceptual modelling.\\nProficiency in statistical analysis tools (R, Python and SAS).\\nExtensive experience solving analytical problems using quantitative approaches (e.g. Bayesian Analysis, Reduced Dimensional Data Representations and Multi-scale Feature Identification).\\nResearch and implement data mining machine learning algorithms in supervised and unsupervised learning areas Good knowledge of NoSQL DB (Mongo/Casandra)\\n\\n(Ref:www.freshersworld.com,freshersworld)', 'Machine Learning AssociatesYou should have a working appreciation of the ML / AI / NLP landscape. You should be at ease with applying algorithms such as Logistic Regression, Decision Trees and Random Forest Ensemble. You should be able to identify the right scenarios with the right tools, and design accordingly.\\n2- 4 years experience in development with Core Java / Java EE, R or Python. At least 1 year working with ML packages.,\\nThis job is provided by Shine.com', 'Are you a backend engineer who wants to learn data science and machine learning? Then this is the role for you! We will train you to work on production AI projects at Helpshift. These AI projects help our customers scale their customer service through automating mundane work as well as assisting customer service agents in doing their work.\\n\\nWhat You Will Continue To Work On\\n\\nYou will continue working on Python, APIs, databases, background jobs, Kafka topics, cloud storage (on AWS and Azure), etc.\\n\\nWhat You Will Learn\\n\\nWe have a fabulous data scientist team who will coach you and introduce you into the world of data science and machine learning. We have excellent engineering teammates who will guide you in your work.\\n\\nWhat You Should Expect\\n\\nThe AI team is split between 2 offices - San Francisco and Pune, India. We have the broader engineering and product teams in the Pune office.\\n\\nThe AI team consists of 2 teams - data scientists (DS) and machine learning engineering (MLE). We are the MLE team.\\n\\nThink of the MLE team\\'s work as \"ML infrastructure\" + \"productionizing data science algorithms\". ML infrastructure work includes APIs, databases, background jobs, Kafka topics, cloud storage (on AWS and Azure), etc. Productionizing data science algorithms include taking the data scientists\\' prototypes and building a robust system that can go into production, and serve large-scale customers (think of the biggest gaming companies in the world, the biggest fintech companies in the world, and so on). You bring your programming skills and backend engineering skills, we will coach you on the rest.\\n\\nWe are small teams operating in a startup environment. Expect fast pace but regular working hours. We strive to deliver quality with speed. However, we will not sacrifice quality for speed.\\n\\nWe are transitioning to practice Agile iterations in developing software, ensuring a concrete deliverable at the end of every cycle.\\n\\nHow Big Is Helpshift\\n\\nHelpshift is installed on over 2 billion devices - roughly 1 out of every 3 smartphones in the world.\\n\\nWe serve over 820 million active users and ~7 million conversations every month.\\n\\nSome More Numbers\\n\\n165000 requests per second\\n\\n50 ms response time\\n\\n~400GB data transfer every hour\\n\\n1000+ VMs deployed at peak\\n\\nWhat We Expect From You\\n\\n2+ years of medium / large scale server-side software development experience\\n\\nProficiency with Python language', 'Developing predictive models in the area of marketing\\nUnderstanding business problems and translating it into data mining problems\\nApplying techniques such as clustering, classification and association\\nWeb analytics, Data mining techniques application for large data.\\nThe key personnel shall also demonstrate experience using advanced analytic techniques such as modern econometric methods, multivariate statistical analysis, clustering and segmentation, experimental design, optimization and text analytics.\\nPredictive models to improve advertiser campaign performance\\nMachine learning models for categorizing web pages and content\\nFraud detection automated ranking content quality\\n,\\nThis job is provided by Shine.com', \"Responsibilities\\nWork with, as needed, customers to understand business challenges and propose new modeling and algorithmic solutions that leverage the latest in statistical and machine learning techniques.\\nWork collaboratively with the rest of the data science team, data engineers, developers and product management to translate business requirements into technical requirements that can be addressed with statistical and machine learning techniques.\\nStudy data sources and find insights/correlation to investigate how data science can be used to solve existing and new business challenges.\\nApply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in the installed base sales automation domain.\\nUse best practices in applying and deploying data science at scale.\\n\\nRequirements\\nStrong sense of and an ability to cultivate an environment of teamwork, and a willingness to help others.\\nAbility to effectively communicate technical concepts to both technical and non- technical staff members and customers.\\nProficiency in data analysis and programming languages such as SQL, Python, and R.\\n2-7 years hands-on experience in machine learning, statistics or experiment design.\\nMaster's Degree required in Statistics, Mathematics, Econometrics, Operations\\nResearch, Computer Science, Physics or a related field with focus on data analysis.\\nExpertise in machine learning, statistics, data analysis.\\nMust have an excellent knowledge of advanced methods, and experience in applying those methods to a variety of problems.\\nSolid grasp of probability, statistical or mathematical modeling with analytical and quantitative problem-solving ability.\\nExperience with time-series analysis would be a plus.\\nDemonstrated experience in applying machine learning to real-world problems\\nFamiliarity with software development cycles, source control systems (including Git), databases, and cloud computing platforms such as AWS.\\nKnowledge of large equipment manufacturing, installed base sales, recurring revenue, and equipment service would be a plus.\", \"Do you want to shape the future of enterprise software?\\n\\nAt Aera Technology, we apply internet scale technology to the challenges facing enterprise businesses. Think of the self-driving car: connected, always-on, thinking, and autonomous. Our mission is to enable companies in the same way. The cognitive technology for the Self-Driving Enterprise™. Aera understands how your business works, makes real-time recommendations, predicts outcomes, and takes action autonomously. Our platform is increasingly used by the world's largest companies to identify and respond to market opportunities faster.\\n\\nAera Technology is looking for a Machine Learning Engineer to work from our Pune office.\\n\\nResponsibilities\\nYou will be responsible for designing, implementing, monitoring and maintaining our machine learning systems that power the Aera platform\\nYou will be working on new and challenging Engineering Problems to operationalize Data Science\\nYou will be working in a highly collaborative environment with other experts in Data Science, Engineering and DevOps teams\\nDesign and implement state of the art Machine Learning approaches\\nBuilding core machine learning infrastructure, which includes distributed systems, abstractions, development tools, model hosting /serving/ inference pipelines\\n\\nAbout You\\nB.E./B.Tech in Computer Science/Computer Engineering\\n5-8 years of experience in software engineering & architecture\\nAt least 2 years of experience in designing and deploying Machine Learning Systems\\nStrong skills with Python\\nExperience in working with large data sets and pipelines, distributed systems for machine learning using frameworks such as Apache Spark\\nExperience in building Machine Learning models and experience using libraries such as scikit-learn, pandas, tensorflow, keras, etc.\\nExperience in technologies like Spark, Hadoop, Kafka\\nTake end-to-end ownership of Machine Learning systems -- from data pipelines and training to the realtime prediction engine\\nExperience in setting up Data and ML Pipelines and ML engineering tools like MLFlow, Data Version Control\\nExperience in building containerized applications/microservices using Docker and Kubernetes\\nExperience in Agile Methodology, CI/CD, Jenkins, GIT & Jira\\nShould possess strong problem-solving skills\\nExcellent verbal and written communication skills\\nYou take complete ownership of your work and are self-driven.\\n\\nOur Environment\\nAWS hosted infrastructure\\nLinux\\nSpark\\nPython\\n\\nAt Aera, we're on a mission to solve the biggest, most intractable challenges of enterprise software. We envision the rise of the Self-Driving Enterprise: a more autonomously functioning business with a central operating system that connects and orchestrates business operations. Our platform is increasingly used by the world's largest companies to identify and respond to market opportunities faster.\\n\\nIf you share our passion for building the next generation of enterprise software and implementing it for the most sophisticated customers in the world, you’ve met your match. Headquartered in Mountain View, California, we're growing fast, with teams in Mountain View and San Francisco (California), Bucharest and Cluj-Napoca (Romania), Paris (France), Munich (Germany), London (UK), Pune (India), and Sydney (Australia). So join us, and let’s build this!\", 'YASH Technologies, a leading enterprise business and technology solution partner for medium and large global customers, is seeking Machine Learning professionals, who thrive on challenges and desires to make a real difference in the business world. With an environment of extraordinary innovation and unprecedented growth, this is an exciting opportunity for a self-starter who enjoys working in a fast-paced, quality-oriented, and team environment.\\n\\nYou are required to have skills in the following areas :\\n\\n6-12 years of IT experience with 3+ years of experience in writing Machine Learning Algorithms.\\nAt least 5 Years of experience in Python or Java services is required.\\nA mathematical background with experience on c lassifications, text processing, image processing with deep learning paradigms, semantic analysis, semantic processing of unstructured data experience is required.\\nHands-on experience with existing Machine Learning Frameworks & Libraries (keras, spacy, Tensorflow)\\nExperience in leading a team of developers/ML engineers in solving and delivering solutions.\\nGood understanding of data structures, data models & software architecture.\\nExperienced in working with Agile teams.\\nExperience in any cloud services (AWS/Azure/Google).\\nHands-on experience in building/fine-tuning models without leveraging machine learning frameworks.\\nExperience with data analytics tools (PowerBI, Spotfire, etc) or languages (Python, R) is an added advantage.', \"Job Reference #\\n189404BR\\n\\nCity\\nPune\\n\\nJob Type\\nFull Time\\n\\nYour role\\nAre you interested in pursuing your career in Asset Management? Does working in a data driven business excite you? Do you want to be part of the data revolution by performing hands on data analysis and developing machine learning models to produce working concepts, along with managing multiple initiatives for cross-functional data analytics needs? We’re looking for data scientist to:\\nprovide thought leadership in predictive modeling and machine learning. NLP and Deep Learning are the two focus areas\\nleverage data assets to build learning systems and predictive models to drive the efficiency of the investment process\\ncollect, cleanse, massage, and organize data\\ndeliver actionable insights to stakeholders through rich visualization and presentation\\ndeploy models into production in a way that is easy to maintain and scalable\\nbuild infrastructure to accelerate the pace of model exploration and improve model serving and maintenance\\nmanage model release cycle\\n\\nYour team\\nChief Data Office (CDO), within UBS Global Asset Management (AM), was established to re-define AM’s data & analytics strategy and to lead the innovation agenda for the division. The CDO provides the foundation for establishing a data and analytics driven culture, by guiding the successful delivery of both foundational and innovative solutions, in support of AM's strategic agenda. To design multi-faceted innovative solutions, the CDO is structured to encompass several functions, including Data Analytics, Data Solutions, and Data Governance. Analytics Center of Excellence team will drive the Analytics agenda for CDO and will be based in India\\n\\nYour expertise\\nPhD or MS degree in Data Science, Operations Research, Applied Math, Statistics, Computer Science, or equivalent\\nideally 5+ years of hands-on experience in developing statistical models, natural language processing, and deep learning models\\nexperience with machine learning APIs and computational packages such as TensorFlow, Theano, PyTorch, Keras, Scikit-Learn, NumPy, SciPy, Pandas, StatsModels, Spark ML\\nexperience with time series data and models is required.\\nexperience with Big Data technologies such as Hadoop, Spark, Kubernetes, Kafka, Arrow,\\ndemonstrated the ability to explain and present your analyses and models to audiences with varying levels of expertise\\ndemonstrated the ability to develop production models and data pipeline in Python\\nexperience with financial markets and time series will be valuable\\nunderstanding of Agile software methodology\\nfluent in English with excellent verbal and written communication skills.\\n\\n\\nAbout Us\\n\\nExpert advice. Wealth management. Investment banking. Asset management. Retail banking in Switzerland. And all the support functions. That's what we do. And we do it for private and institutional clients as well as corporations around the world.\\n\\nWe are about 60,000 employees in all major financial centers, in more than 50 countries. Do you want to be one of us?\\n\\nJoin us\\nAre you truly collaborative? Succeeding at UBS means respecting, understanding and trusting colleagues and clients. Challenging others and being challenged in return. Being passionate about what you do. Driving yourself forward, always wanting to do things the right way. Does that sound like you? Then you have the right stuff to join us. Apply now.\\n\\nDisclaimer / Policy Statements\\nUBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce.\", \"Jd\\nHandling business problems and come with attractive solutions and be a team player\\nExtensively working into information extraction in NLP\\nWorking into open source data science technologies\\nSecondary research to find apt and latest methodology required to solve the current business problem.\\nExperience with general NLP tasks and techniques, such as parsing, text pre-processing, NER, entity linking, relation extraction, etc.\\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\nBuild POC's for data projects to navigate decisions for product enhancements\\nBuild real-time models leveraging NLP for targeted computations\\nEstablish machine learning techniques for path to automating manual workflows\\nWork closely with data engineers and product teams to solve real world problems\\nHands-on implementation of Common data processing technique.\\n(ref:hirist.com)\", 'Python Developer Job Description\\n\\nPython Developer job description is to attract experienced developers who can build functional server-side applications.\\n\\nPython Developer Responsibilities Include\\nBuilding efficient server-side applications\\nIntegrating front-end components into applications\\nChecking code from other developers and coaching junior team members\\nJob Brief\\nWe are looking for a Python Developer to build functional and efficient server-side applications.\\nPython Developer responsibilities include participating in all phases of the software development lifecycle and coaching junior developers. If you- re a seasoned developer with a love for back-end technologies, we- d like to meet you.\\nYour ultimate goal is to create high-quality products that meet customer needs.\\nResponsibilities\\nHelp design and implement functional requirements\\nBuild efficient back-end features in Python\\nIntegrate front-end components into applications\\nManage testing and bug fixes\\nPrepare technical documentation\\nCollaborate with UX/UI designers to implement design into the code\\nRequirements\\n4+ Years of experience as Python Developer\\nExperience with Python frameworks (e.g. Django, Flask, Sanic, Bottle)\\nFamiliarity with Amazon Web Services (AWS) and REST API\\nWorked on different databases like MS SQL, MySQL, PostgreSQL, MongoDB.\\nKnowledge of JavaScript, Jquery, NodeJS and AngularJS framework\\nSkills\\nMachine Learning\\nPython\\nComputer Vision\\nDeep Learning\\nTensorflow\\nNatural Language Processing / Natural Language Understanding\\nKeras\\nChat Bot / Voice Bot / Email Bot Development\\nTools & Tech : Python, Dialogflow, AWS Cloud, NLP, PostgreSQL, Pandas, AWS Lambda, Docker, Flask, Spacy, BERT, JIRA/ Phabricator\\n(ref:hirist.com)', 'Experience: 6 to 7.5 Years\\n\\nJob Location:Pune\\n\\nDuration of Contract for 6 Months\\n\\nNotice period :only 15 days\\n\\nPython/Machine Learning and Web Development all mandatory\\n\\nRegards,\\n\\nJane Masih\\n\\n8879389007\\n\\nThis job is provided by Shine.com', \"Description\\n\\nMachine Learning (ML) has been strategic to Amazon from the early years. We are pioneers in areas such as recommendation engines, product search, eCommerce fraud detection, and large-scale optimization of fulfillment center operations. The ML team within Amazon Internet Services Private Limited (“AISPL”) provides opportunities to innovate in a fast-paced organization that contributes to game-changing projects and technologies that get deployed on devices and the cloud. As a Deep Learning Architect in AISPL, you'll partner with business and other support teams of AISPL to build new services that surprise and delight our customers. You will be working with terabytes of text, images, and other types of data to solve real-world problems.\\n\\nWe’re looking for top architects, system and software engineers in AISPL capable of using ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems. We are open for locations across India.\\n\\nThe Primary Responsibilities Of This Role Are To\\nUse ML tools, such as Amazon SageMaker and Amazon Simple Storage Service, to provide a scalable cloud environment for our customers to label data, build, train, tune and deploy their models\\nCollaborate with our data scientists to create scalable ML solutions for business problems\\nInteract with AISPL customer directly to understand the business problem, help and aid them in implementation of their ML ecosystem\\nAnalyze and extract relevant information from large amounts of historical data to help automate and optimize key processes\\nWork closely with account team, research scientist teams and product engineering teams to drive model implementations and new algorithms\\n\\nBasic Qualifications\\nBS in computer science, or related technical, math, or scientific field\\n7+ years of professional experience in a business environment\\n5+ years of relevant experience in building large scale enterprise IT systems\\n1+ year of public cloud computing experience in AWS Cloud\\n1+ year of experience hosting and deploying ML solutions (e.g., for training, tuning, and inferences)\\nPreferred Qualifications\\nMasters or PhD degree in computer science, or related technical, math, or scientific field\\nStrong working knowledge of deep learning, machine learning and statistics.\\nHands on experience building models with deep learning frameworks like MXNet, Tensorflow, Caffe, Torch, Theano or similar.\\nHands on experience with deep learning (e.g., CNN, RNN, LSTM)\\nExperience in using Python, R or Matlab or other statistical/machine learning software\\nStrong communication and data presentation skills\\nThe motivation to achieve results in a fast-paced environment.\\nExperience with statistical modelling / machine learning\\nStrong attention to detail\\nComfortable working in a fast paced, highly collaborative, dynamic work environment\\nAbility to think creatively and solve problems\\n\\nCompany - AISPL - Maharashtra\\nJob ID: A931543\", 'Role Summary/Purpose:\\n\\n\\n\\n\\nBaker Hughes seeks an experienced Data Analysts to manage and perform data cleansing and mining duties for wireline services product development, geoscience and sustaining projects at the Baker Hughes GEC center in Pune. The successful candidate will be accountable for developing and delivering conclusions based on numbers, trends and data types of projects executed globally.\\n\\nEssential Responsibilities:\\n\\n\\nWork with variety of large amount of geophysical data for cleansing, mining and analyzing to find conclusions\\nPresent findings and data translation into clear understandable implementation ideas\\nMachine learning – building data models (neural network, Random Forrest and others as applicable\\nMath and statistics skills are needed\\nKnowledge and experience of deep learning is a plus\\n\\n\\nQualifications/Requirements:\\n\\n\\nBachelor degree in field of math, statistics or computer science from a recognized university with\\n3 years experience minimum\\nMaster’s degree is preferred Knowledge of upstream Oil and Gas industry Experience of working with a wide range of stakeholders including operations, sourcing, product management and project management organizations\\nExperience of working in a matrix, multicultural environment\\n\\n\\nDesired Characteristics:\\n\\n\\nPython and R programming experience and portfolio showcase\\nExperience working with SAP and Clarity is desired\\nExcellent written and verbal communications skills.\\nAbility to work in a team and use own initiative\\n\\n\\nLocations:\\n\\nPune, India\\n\\nThis is your opportunity to learn more, do more, live the career you have imagined and be part of a truly diverse organization.\\n\\nBaker Hughes is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law. Learn more', 'Short Description\\n\\nWe are looking for Machine Learning with Bigdata for 4 Years to 6 years in Pune.\\n\\nQualifications\\n\\nB.E/B.Tech/M.E/M.Tech\\n\\nJob Responsibilities\\n\\nWe are looking to hire Machine Learning with Bigdata for 4 Years to 6 years in Pune.\\n\\nRole Description (Role & Responsibilities)\\nCondidate should have 4 to 6 years core experience in Machine vision systems Image processing modeling and simulation\\nCandidate should have 4 to 6 years core Python and R development\\nExperience with minimum one year in TensorFlow programming\\nExperience in maths and stats applied in Machine Learning algorithms hands on with applying ML algorithms and solution validation\\nStrong programming fundamentals Experience in Inferential statistics and modeling\\nExposure to database concepts and complex SQL queries Exposure of standard V and V concepts and activities configuration management\\nLocation: Pune\\nExperience: 4 - 6 years\\n\\nPrimary Skills (Must Have)\\nMachine Learing\\nAlgorithms', 'Accenture Technology powers our clients’ businesses with innovative technologies—established and emerging—changing the way their people and customers experience work, life and entertainment. Join Accenture Technology and you’ll translate the operational needs of the world’s governments and leading businesses into the innovative technical solutions that will enable them to better serve their customers—your friends, family and neighbors.You’ll deliver everything from point solutions for a single business function to large, long-term outsourcing services, to complex systems integration installations spanning multiple businesses and functions. You’ll create custom-designed solutions or integrate our technology platforms with their operations.\\n\\nRole :Application Developer Role Description :Design, build and configure applications to meet business process and application requirements. Must Have Skills :Computer Vision,TensorFlow Good To Have Skills : Job Requirements : 1:Responsibilities A:Methods for acquiring,processing,analyzing understing digital images B:Develop algorithms applications related to image video processing that perform functions such as object identification classification C:Review integrate all application requirements,including functional,security,integration,performance,quality operations requirements Review integrate the Technical Architecture requirements Provide input into final decisions regarding hardware,network products,system software security 2:Professional Experience Must have Skills : A:Machine learning exposure B:Deep learning/Google TensorFlow/Python for Machine Learning eg scikit-learn Good to Have: A:Open source ML libraries tools like Apache Mahout,Apache Spark\\n15 years of full time education', 'Manager / Senior ManagerPOSITION TITLE: Marketing or Customer AnalyticsROLE & RESPONSIBILITIES As a part of Marketing & Customer Analytics team your primary responsibility will be to support Marketing team and provide actionable insights to measure, manage and analyze all marketing related activities. In this role you are required to do analysis and solving moderate to complex marketing analytics problem.\\nYou would be a single point of contact for all Campaign Analytics related activities, provide recommendations to marketing team and analyze the effectiveness of marketing campaigns using ROI calculations.\\nUnderstanding Customer behavior and segment customers based on the available data points so that marketing team can target the right set of customers.\\nThe person will have generally, interacts with senior management or leadership levels, and requires understanding of the strategic direction set by senior management.\\nThe person should typically be able to create new solutions or strategy leveraging data with or without adapting existing methods and procedures.\\nShould be able to work independently or require minimal guidance while working on new projects or problems.\\nThe successful candidate will be responsible for developing, analyzing and executing ideas and initiatives designed to achieve business growth and loss mitigation goals. Other requirements are as follows -\\nLook at providing solutions that go beyond traditional methods\\n\\nUsing advanced machine learning technologies and new data sources.\\nDevelop next-gen modeling capabilities to deliver best in class predictive modeling solutions.\\nShould have hands on experience with some of the marketing analytics solution using machine learning algorithm.\\nHas worked on projects involving large datasets running in TBs, on both structured and unstructured datasets\\nIndependently manage development and implementation of effective marketing mix strategies that help reduce cost of acquisition for the organization.-\\n\\nLiaising internally with business stakeholders, including explaining model outputs, performing ad-hoc analysis and answering technical or background questions on the models and requirements.\\nTo define, analyze, implement, and monitor marketing strategies.\\nMust have capability to clearly communicate analysis\\nMust be able to effectively provide updates and communicate key initiatives to senior managementTechnical capability\\nHands on experience with SQL (or similar structured on non-structured database).\\nHands on experience with Tableau (or similar tools). (ref:iimjobs.com)', 'Responsibilities\\nModel the problem into a DL framework\\nBuild, measure and iterate on neural network architectures that effectively solve the problem\\nBenchmark, validate and test the solution for real-world environments\\nOptimise the solution for accuracy and performance\\n\\nRequirements\\nSkill(s) required: Experience wirh Deep Learning Programming.\\nHave relevant skills and interests\\nHave prior knowledge and experience with Deep Learning for image/video related problems\\nGood to have: hands-on experience with Tensorflow and Python\\nHas done Deep Learning courses, perhaps on MOOCs such as Coursera, Udacity, etc', 'Company Name: MarketsandMarkets\\n Company Website: www.marketsandmarkets.com\\nJob Location: This is a full time role based out of our HO in Pune\\nDesignation: Vice President Product Development\\n\\n\\nOur Product Brief\\n• Our aim is to disrupt the current market leader in technology research—a three-billion-dollar company.\\n• The aforementioned market leader’s flagship product is limited in breadth and depth, biased, not transparent, not scalable, and less insightful for improving ratings.\\n• The company conforms to the ideology that one solution fits all; an unfeasible outlook in today’s market conditions.\\n• Our product/platform aims to provide actionable insights to enable B2B provider-side companies to improve their ratings and market position as well as buyer-side companies to benchmark the best providers. Our product has dual IP, our own research repository and technology already built in. It has a technology stack comprising machine learning, big data, and cognitive computing. By leveraging our proprietary research, the platform will be well poised to meaningfully triangulate public data, enterprise data, and our own proprietary data.\\n• The platform will utilize a multidimensional hierarchical approach to capture insights and accurately analyze available data to ascertain the best providers.\\n• The platform will also use a digitalized approach to capture strengths and weaknesses and will have a dynamic rating mechanism with deep dive critical capabilities for more than 10,000 technologies (quadrants) across multiple industries.\\n• The platform has the potential to evolve into a first-of-its-kind marketplace for the $3.7 trillion global tech spend.\\n• The platform is nearing completion from a technology standpoint, has a renewed UX-UI, and is almost ready for market launch.\\n\\n\\nRole and Expectation\\nYou shall be responsible for the successful commercialization and go-to market of the product/platform as well as its optimization to best suit the needs of the target audience.\\nYou shall also be responsible for achieving the strategic, financial, technical, and operational goals pertaining to our product.\\nAs part of your role, you shall be required to strategize and execute a robust milestone-based plan. The product, being extremely disruptive, needs aggressive execution to reach high acceptance before it goes viral.\\nTo this end, it may be necessary to trade-off between available resources, infrastructure, and technology to prioritize certain aspects of your product launch strategy.\\n\\nOver 95,000 B2B companies have approached us; we have more than 7,500 clients worldwide including 80% of Forbes Global 2000 companies. You can choose multiple ways to bring the product to the market, including leveraging our existing client base.\\n\\nOther expectations would include:\\n1. For maximum effectiveness, it would be crucial to meet vendor-side and buyer-side expectations to lure them to the platform.\\n2. It would be imperative to trade-off between building enough critical mass for a minimal viable product and providing world-class experience with all bells and whistles.\\n3. It would also be important to trade-off between what is already built versus a full-fledged product meeting most of clients’ expectations, keeping the end goal of going to market quicker in mind.\\nYou should have 15+ years of previous experience in developing a large successful product-driven business model alongside building an end-to-end digitalized client engagement from client acquisition to post-sale engagement.\\nExperience in big data, machine learning, data crowdsourcing, and cognitive computing is preferred. A detailed understanding of technology would be an add-on.', 'Technology Support Operations- Specialist\\n\\nIN-Pune\\nFICO (NYSE: FICO) is a leading global analytics software company, helping businesses in 90+ countries make better decisions. Join our world-class team today and fulfill your career potential!\\n\\nJob Summary\\n\\nPune NOC L1 engineer support candidate needed with Linux knowledge and fluent communication.\\n\\nJob Description\\n\\nPosition Title : Technology Support Operations Engineer I\\n\\nAbout FICO\\n\\nFICO (NYSE: FICO) is a leading analytics software company, helping businesses in 90+ countries make better decisions that drive higher levels of growth, profitability and customer satisfaction. The company’s groundbreaking use of Big Data and mathematical algorithms to predict consumer behavior has transformed entire industries.\\n\\nFICO provides analytics software and tools used across multiple industries to manage risk, fight fraud, build more profitable customer relationships, optimize operations and meet strict government regulations. Many of our products reach industry-wide adoption — such as the FICO® Score, the standard measure of consumer credit risk in the United States. FICO solutions leverage open-source standards and cloud computing to maximize flexibility, speed deployment and reduce costs. The company also helps millions of people manage their personal credit health. FICO: Make every decision count™.\\n\\nFounded in 1956, FICO introduced analytic solutions such as credit scoring that have made credit more widely available, not just in the United States but around the world. We have pioneered the development and application of critical technologies behind decision management. These include predictive analytics, business rules management and optimization. We use these technologies to help businesses improve the precision, consistency and agility of their complex, high–volume decisions.\\n\\nSkills Required\\nExperience providing application support in Linux/Unix environment\\nExperience in MySQL database\\nShould be well versed with change and incident management skills\\nOpen to work 24 * 7 environment\\nGood Communication skills\\nWhy Make a Move to FICO?\\nAt FICO, you can develop your career with a leading organization in one of the fastest-growing fields in technology today – Big Data analytics. You’ll play a part in our commitment to help businesses use data to improve every choice they make, using advances in artificial intelligence, machine learning, predictive and prescriptive modeling, and much more.\\n\\nFICO makes a real difference in the way businesses operate worldwide:\\nCredit Scoring — 150+ billion FICO Scores have been sold to date, making it the most used credit score in the world.\\nFraud Detection and Security — 2.6+ billion payment cards globally are protected by FICO fraud systems.\\nLending — 3/4 of US mortgages are approved using the FICO Score.\\nAnti-Money Laundering — our solutions check more than half a billion transactions a day to prevent criminal schemes such as terrorist financing\\n\\nGlobal trends toward digital transformation have created tremendous demand for FICO’s solutions, placing us among the world’s top 100 software companies by revenue. We support many of the world’s largest banks, insurers, retailers, telecommunications providers and other firms reach a new level of success.\\n\\nOur success is dependent on really talented people – just like you– who thrive on the collaboration and innovation that’s nurtured by a diverse and inclusive environment. We’ll provide the support you need, while ensuring you have the freedom to develop your skills and grow your career. Join FICO and help change the way business thinks!\\n\\nLearn more about how you can fulfill your potential at www.fico.com/Careers\\n\\nFICO values the benefit that diversity and a culture of inclusion bring to our workplace. We are an equal employment opportunity and affirmative action employer and we’re proud to offer employment and advancement opportunities to all applicants without regard to race, color, ancestry, religion, sex, national origin, pregnancy, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\\n\\nPosted 12 Days Ago Full time 22667\\n\\nFICO (NYSE: FICO) is a leading global analytics software company, supporting businesses in 90+ countries make better decisions. Join our world-class team today and fulfill your career potential!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBaQWIWzJCgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vih1D9K3JCgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(li1[1])\n",
        "#df = pd.DataFrame(li1) \n",
        "#df\n",
        "with open('element.txt', 'w') as f:\n",
        "    for item in li1:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBS9iRArJCgq",
        "colab_type": "code",
        "outputId": "e16eca13-9ead-4b67-a92a-74f314aa1547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "filename = 'element.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "#print(text)\n",
        "file.close()\n",
        "#type(text)\n",
        "\n",
        "words = text.split()\n",
        "\n",
        "print(words[:200])\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Responsibilities', 'Implementation', 'of', 'advanced', 'deep', 'learning', 'algorithms', 'for', 'sleep', 'stage', 'classification.', 'Development', 'of', 'advanced', 'models', 'with', 'the', 'combination', 'of', 'CNN', 'and', 'RNN.', 'Developing', 'advanced', 'algorithms', 'that', 'solve', 'problems', 'of', 'large', 'dimensionality', 'in', 'a', 'computationally', 'efficient', 'and', 'statistically', 'effective', 'manner.', 'Implementing', 'statistical', 'and', 'data', 'mining', 'techniques', 'e.g.', 'hypothesis', 'testing,', 'machine', 'learning,', 'and', 'retrieval', 'processes', 'on', 'a', 'large', 'amount', 'of', 'data', 'to', 'identify', 'trends,', 'patterns', 'and', 'other', 'relevant', 'information.', 'Collaborating', 'with', 'clients', 'and', 'other', 'stakeholders', 'to', 'effectively', 'integrate', 'and', 'communicate', 'analysis', 'findings.', 'Mentoring', 'and', 'providing', 'project', 'management', 'support', 'to', 'the', 'Associates', 'on', 'the', 'team.', 'Evaluating', 'emerging', 'data-sets', 'and', 'technologies', 'that', 'may', 'contribute', 'to', 'our', 'existing', 'analytical', 'platforms.', 'Establish', 'the', 'scope', 'of', 'the', 'project,', 'lead', 'internal', 'communication', 'with', 'stakeholders,', 'and', 'ensure', 'delivery', 'of', 'the', 'project', 'per', 'commitment.', 'Contributing', 'to', 'the', 'thought', 'leadership', 'of', 'the', 'company', 'by', 'helping', 'in', 'researching', 'the', 'evolving', 'topics', 'and', 'publishing', 'them.', 'Requirements', 'Min', '6', 'years', 'of', 'work', 'experience', 'in', 'data', 'analysis.', 'Strong', 'knowledge', 'in', 'deep', 'learning', 'and', 'artificial', 'intelligence', '(min.', '5', \"years'experience).\", 'Having', 'hands-on', 'experience', 'on', 'advanced', 'analytics', 'concepts', 'and', 'algorithms', '(e.g.', 'Regression', 'analysis', 'Logistic', 'Regression/Decision', 'Tree,', 'Time', 'series', 'analysis,', 'Support', 'Vector', 'Machine,', 'Neural', 'Network', 'etc.).', 'Proficient', 'in', 'Python', 'language', '(Tensor', 'Flow', 'and', 'Keras).', 'Strong', 'knowledge', 'of', 'statistics.', 'Good']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIvjXY1yZYOd",
        "colab_type": "code",
        "outputId": "1a72ce99-fd6c-41a4-8651-43f5ff6f7f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvU_aC56JCgu",
        "colab_type": "code",
        "outputId": "a46ef650-8866-4c77-979b-e9509af1be06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "filtered_sentence = [] \n",
        "\n",
        "\n",
        "for w in words: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w) \n",
        "\n",
        "print(filtered_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Responsibilities', 'Implementation', 'advanced', 'deep', 'learning', 'algorithms', 'sleep', 'stage', 'classification.', 'Development', 'advanced', 'models', 'combination', 'CNN', 'RNN.', 'Developing', 'advanced', 'algorithms', 'solve', 'problems', 'large', 'dimensionality', 'computationally', 'efficient', 'statistically', 'effective', 'manner.', 'Implementing', 'statistical', 'data', 'mining', 'techniques', 'e.g.', 'hypothesis', 'testing,', 'machine', 'learning,', 'retrieval', 'processes', 'large', 'amount', 'data', 'identify', 'trends,', 'patterns', 'relevant', 'information.', 'Collaborating', 'clients', 'stakeholders', 'effectively', 'integrate', 'communicate', 'analysis', 'findings.', 'Mentoring', 'providing', 'project', 'management', 'support', 'Associates', 'team.', 'Evaluating', 'emerging', 'data-sets', 'technologies', 'may', 'contribute', 'existing', 'analytical', 'platforms.', 'Establish', 'scope', 'project,', 'lead', 'internal', 'communication', 'stakeholders,', 'ensure', 'delivery', 'project', 'per', 'commitment.', 'Contributing', 'thought', 'leadership', 'company', 'helping', 'researching', 'evolving', 'topics', 'publishing', 'them.', 'Requirements', 'Min', '6', 'years', 'work', 'experience', 'data', 'analysis.', 'Strong', 'knowledge', 'deep', 'learning', 'artificial', 'intelligence', '(min.', '5', \"years'experience).\", 'Having', 'hands-on', 'experience', 'advanced', 'analytics', 'concepts', 'algorithms', '(e.g.', 'Regression', 'analysis', 'Logistic', 'Regression/Decision', 'Tree,', 'Time', 'series', 'analysis,', 'Support', 'Vector', 'Machine,', 'Neural', 'Network', 'etc.).', 'Proficient', 'Python', 'language', '(Tensor', 'Flow', 'Keras).', 'Strong', 'knowledge', 'statistics.', 'Good', 'knowledge', 'project', 'management', 'software.', 'Machine', 'Learning/', 'Data', 'Scientist', 'Job', 'Requirements', 'Minimum', 'two', 'years', 'experience', 'Machine', 'Learning', 'technologies', 'Expert', 'building', 'custom', 'ML', 'algorithms', 'leveraging', 'statistical', 'concepts', 'ML', 'tools', 'Apply', 'machine', 'learning,', 'data', 'mining,', 'predictive', 'modelling', '&', 'statistical', 'techniques', 'create', 'new', 'scalable', 'models.', 'Understanding', '&', 'working', 'knowledge', 'Natural', 'Language', 'Processing', '&', 'Conceptual', 'modelling.', 'Proficiency', 'statistical', 'analysis', 'tools', '(R,', 'Python', 'SAS).', 'Extensive', 'experience', 'solving', 'analytical', 'problems', 'using', 'quantitative', 'approaches', '(e.g.', 'Bayesian', 'Analysis,', 'Reduced', 'Dimensional', 'Data', 'Representations', 'Multi-scale', 'Feature', 'Identification).', 'Research', 'implement', 'data', 'mining', 'machine', 'learning', 'algorithms', 'supervised', 'unsupervised', 'learning', 'areas', 'Good', 'knowledge', 'NoSQL', 'DB', '(Mongo/Casandra)', '(Ref:www.freshersworld.com,freshersworld)', 'Machine', 'Learning', 'AssociatesYou', 'working', 'appreciation', 'ML', '/', 'AI', '/', 'NLP', 'landscape.', 'You', 'ease', 'applying', 'algorithms', 'Logistic', 'Regression,', 'Decision', 'Trees', 'Random', 'Forest', 'Ensemble.', 'You', 'able', 'identify', 'right', 'scenarios', 'right', 'tools,', 'design', 'accordingly.', '2-', '4', 'years', 'experience', 'development', 'Core', 'Java', '/', 'Java', 'EE,', 'R', 'Python.', 'At', 'least', '1', 'year', 'working', 'ML', 'packages.,', 'This', 'job', 'provided', 'Shine.com', 'Are', 'backend', 'engineer', 'wants', 'learn', 'data', 'science', 'machine', 'learning?', 'Then', 'role', 'you!', 'We', 'train', 'work', 'production', 'AI', 'projects', 'Helpshift.', 'These', 'AI', 'projects', 'help', 'customers', 'scale', 'customer', 'service', 'automating', 'mundane', 'work', 'well', 'assisting', 'customer', 'service', 'agents', 'work.', 'What', 'You', 'Will', 'Continue', 'To', 'Work', 'On', 'You', 'continue', 'working', 'Python,', 'APIs,', 'databases,', 'background', 'jobs,', 'Kafka', 'topics,', 'cloud', 'storage', '(on', 'AWS', 'Azure),', 'etc.', 'What', 'You', 'Will', 'Learn', 'We', 'fabulous', 'data', 'scientist', 'team', 'coach', 'introduce', 'world', 'data', 'science', 'machine', 'learning.', 'We', 'excellent', 'engineering', 'teammates', 'guide', 'work.', 'What', 'You', 'Should', 'Expect', 'The', 'AI', 'team', 'split', '2', 'offices', '-', 'San', 'Francisco', 'Pune,', 'India.', 'We', 'broader', 'engineering', 'product', 'teams', 'Pune', 'office.', 'The', 'AI', 'team', 'consists', '2', 'teams', '-', 'data', 'scientists', '(DS)', 'machine', 'learning', 'engineering', '(MLE).', 'We', 'MLE', 'team.', 'Think', 'MLE', \"team's\", 'work', '\"ML', 'infrastructure\"', '+', '\"productionizing', 'data', 'science', 'algorithms\".', 'ML', 'infrastructure', 'work', 'includes', 'APIs,', 'databases,', 'background', 'jobs,', 'Kafka', 'topics,', 'cloud', 'storage', '(on', 'AWS', 'Azure),', 'etc.', 'Productionizing', 'data', 'science', 'algorithms', 'include', 'taking', 'data', \"scientists'\", 'prototypes', 'building', 'robust', 'system', 'go', 'production,', 'serve', 'large-scale', 'customers', '(think', 'biggest', 'gaming', 'companies', 'world,', 'biggest', 'fintech', 'companies', 'world,', 'on).', 'You', 'bring', 'programming', 'skills', 'backend', 'engineering', 'skills,', 'coach', 'rest.', 'We', 'small', 'teams', 'operating', 'startup', 'environment.', 'Expect', 'fast', 'pace', 'regular', 'working', 'hours.', 'We', 'strive', 'deliver', 'quality', 'speed.', 'However,', 'sacrifice', 'quality', 'speed.', 'We', 'transitioning', 'practice', 'Agile', 'iterations', 'developing', 'software,', 'ensuring', 'concrete', 'deliverable', 'end', 'every', 'cycle.', 'How', 'Big', 'Is', 'Helpshift', 'Helpshift', 'installed', '2', 'billion', 'devices', '-', 'roughly', '1', 'every', '3', 'smartphones', 'world.', 'We', 'serve', '820', 'million', 'active', 'users', '~7', 'million', 'conversations', 'every', 'month.', 'Some', 'More', 'Numbers', '165000', 'requests', 'per', 'second', '50', 'ms', 'response', 'time', '~400GB', 'data', 'transfer', 'every', 'hour', '1000+', 'VMs', 'deployed', 'peak', 'What', 'We', 'Expect', 'From', 'You', '2+', 'years', 'medium', '/', 'large', 'scale', 'server-side', 'software', 'development', 'experience', 'Proficiency', 'Python', 'language', 'Developing', 'predictive', 'models', 'area', 'marketing', 'Understanding', 'business', 'problems', 'translating', 'data', 'mining', 'problems', 'Applying', 'techniques', 'clustering,', 'classification', 'association', 'Web', 'analytics,', 'Data', 'mining', 'techniques', 'application', 'large', 'data.', 'The', 'key', 'personnel', 'shall', 'also', 'demonstrate', 'experience', 'using', 'advanced', 'analytic', 'techniques', 'modern', 'econometric', 'methods,', 'multivariate', 'statistical', 'analysis,', 'clustering', 'segmentation,', 'experimental', 'design,', 'optimization', 'text', 'analytics.', 'Predictive', 'models', 'improve', 'advertiser', 'campaign', 'performance', 'Machine', 'learning', 'models', 'categorizing', 'web', 'pages', 'content', 'Fraud', 'detection', 'automated', 'ranking', 'content', 'quality', ',', 'This', 'job', 'provided', 'Shine.com', 'Responsibilities', 'Work', 'with,', 'needed,', 'customers', 'understand', 'business', 'challenges', 'propose', 'new', 'modeling', 'algorithmic', 'solutions', 'leverage', 'latest', 'statistical', 'machine', 'learning', 'techniques.', 'Work', 'collaboratively', 'rest', 'data', 'science', 'team,', 'data', 'engineers,', 'developers', 'product', 'management', 'translate', 'business', 'requirements', 'technical', 'requirements', 'addressed', 'statistical', 'machine', 'learning', 'techniques.', 'Study', 'data', 'sources', 'find', 'insights/correlation', 'investigate', 'data', 'science', 'used', 'solve', 'existing', 'new', 'business', 'challenges.', 'Apply', 'statistical', 'analysis', 'modeling', 'techniques', 'small', 'large', 'datasets', 'solve', 'specific', 'business', 'problems', 'installed', 'base', 'sales', 'automation', 'domain.', 'Use', 'best', 'practices', 'applying', 'deploying', 'data', 'science', 'scale.', 'Requirements', 'Strong', 'sense', 'ability', 'cultivate', 'environment', 'teamwork,', 'willingness', 'help', 'others.', 'Ability', 'effectively', 'communicate', 'technical', 'concepts', 'technical', 'non-', 'technical', 'staff', 'members', 'customers.', 'Proficiency', 'data', 'analysis', 'programming', 'languages', 'SQL,', 'Python,', 'R.', '2-7', 'years', 'hands-on', 'experience', 'machine', 'learning,', 'statistics', 'experiment', 'design.', \"Master's\", 'Degree', 'required', 'Statistics,', 'Mathematics,', 'Econometrics,', 'Operations', 'Research,', 'Computer', 'Science,', 'Physics', 'related', 'field', 'focus', 'data', 'analysis.', 'Expertise', 'machine', 'learning,', 'statistics,', 'data', 'analysis.', 'Must', 'excellent', 'knowledge', 'advanced', 'methods,', 'experience', 'applying', 'methods', 'variety', 'problems.', 'Solid', 'grasp', 'probability,', 'statistical', 'mathematical', 'modeling', 'analytical', 'quantitative', 'problem-solving', 'ability.', 'Experience', 'time-series', 'analysis', 'would', 'plus.', 'Demonstrated', 'experience', 'applying', 'machine', 'learning', 'real-world', 'problems', 'Familiarity', 'software', 'development', 'cycles,', 'source', 'control', 'systems', '(including', 'Git),', 'databases,', 'cloud', 'computing', 'platforms', 'AWS.', 'Knowledge', 'large', 'equipment', 'manufacturing,', 'installed', 'base', 'sales,', 'recurring', 'revenue,', 'equipment', 'service', 'would', 'plus.', 'Do', 'want', 'shape', 'future', 'enterprise', 'software?', 'At', 'Aera', 'Technology,', 'apply', 'internet', 'scale', 'technology', 'challenges', 'facing', 'enterprise', 'businesses.', 'Think', 'self-driving', 'car:', 'connected,', 'always-on,', 'thinking,', 'autonomous.', 'Our', 'mission', 'enable', 'companies', 'way.', 'The', 'cognitive', 'technology', 'Self-Driving', 'Enterprise™.', 'Aera', 'understands', 'business', 'works,', 'makes', 'real-time', 'recommendations,', 'predicts', 'outcomes,', 'takes', 'action', 'autonomously.', 'Our', 'platform', 'increasingly', 'used', \"world's\", 'largest', 'companies', 'identify', 'respond', 'market', 'opportunities', 'faster.', 'Aera', 'Technology', 'looking', 'Machine', 'Learning', 'Engineer', 'work', 'Pune', 'office.', 'Responsibilities', 'You', 'responsible', 'designing,', 'implementing,', 'monitoring', 'maintaining', 'machine', 'learning', 'systems', 'power', 'Aera', 'platform', 'You', 'working', 'new', 'challenging', 'Engineering', 'Problems', 'operationalize', 'Data', 'Science', 'You', 'working', 'highly', 'collaborative', 'environment', 'experts', 'Data', 'Science,', 'Engineering', 'DevOps', 'teams', 'Design', 'implement', 'state', 'art', 'Machine', 'Learning', 'approaches', 'Building', 'core', 'machine', 'learning', 'infrastructure,', 'includes', 'distributed', 'systems,', 'abstractions,', 'development', 'tools,', 'model', 'hosting', '/serving/', 'inference', 'pipelines', 'About', 'You', 'B.E./B.Tech', 'Computer', 'Science/Computer', 'Engineering', '5-8', 'years', 'experience', 'software', 'engineering', '&', 'architecture', 'At', 'least', '2', 'years', 'experience', 'designing', 'deploying', 'Machine', 'Learning', 'Systems', 'Strong', 'skills', 'Python', 'Experience', 'working', 'large', 'data', 'sets', 'pipelines,', 'distributed', 'systems', 'machine', 'learning', 'using', 'frameworks', 'Apache', 'Spark', 'Experience', 'building', 'Machine', 'Learning', 'models', 'experience', 'using', 'libraries', 'scikit-learn,', 'pandas,', 'tensorflow,', 'keras,', 'etc.', 'Experience', 'technologies', 'like', 'Spark,', 'Hadoop,', 'Kafka', 'Take', 'end-to-end', 'ownership', 'Machine', 'Learning', 'systems', '--', 'data', 'pipelines', 'training', 'realtime', 'prediction', 'engine', 'Experience', 'setting', 'Data', 'ML', 'Pipelines', 'ML', 'engineering', 'tools', 'like', 'MLFlow,', 'Data', 'Version', 'Control', 'Experience', 'building', 'containerized', 'applications/microservices', 'using', 'Docker', 'Kubernetes', 'Experience', 'Agile', 'Methodology,', 'CI/CD,', 'Jenkins,', 'GIT', '&', 'Jira', 'Should', 'possess', 'strong', 'problem-solving', 'skills', 'Excellent', 'verbal', 'written', 'communication', 'skills', 'You', 'take', 'complete', 'ownership', 'work', 'self-driven.', 'Our', 'Environment', 'AWS', 'hosted', 'infrastructure', 'Linux', 'Spark', 'Python', 'At', 'Aera,', \"we're\", 'mission', 'solve', 'biggest,', 'intractable', 'challenges', 'enterprise', 'software.', 'We', 'envision', 'rise', 'Self-Driving', 'Enterprise:', 'autonomously', 'functioning', 'business', 'central', 'operating', 'system', 'connects', 'orchestrates', 'business', 'operations.', 'Our', 'platform', 'increasingly', 'used', \"world's\", 'largest', 'companies', 'identify', 'respond', 'market', 'opportunities', 'faster.', 'If', 'share', 'passion', 'building', 'next', 'generation', 'enterprise', 'software', 'implementing', 'sophisticated', 'customers', 'world,', 'you’ve', 'met', 'match.', 'Headquartered', 'Mountain', 'View,', 'California,', \"we're\", 'growing', 'fast,', 'teams', 'Mountain', 'View', 'San', 'Francisco', '(California),', 'Bucharest', 'Cluj-Napoca', '(Romania),', 'Paris', '(France),', 'Munich', '(Germany),', 'London', '(UK),', 'Pune', '(India),', 'Sydney', '(Australia).', 'So', 'join', 'us,', 'let’s', 'build', 'this!', 'YASH', 'Technologies,', 'leading', 'enterprise', 'business', 'technology', 'solution', 'partner', 'medium', 'large', 'global', 'customers,', 'seeking', 'Machine', 'Learning', 'professionals,', 'thrive', 'challenges', 'desires', 'make', 'real', 'difference', 'business', 'world.', 'With', 'environment', 'extraordinary', 'innovation', 'unprecedented', 'growth,', 'exciting', 'opportunity', 'self-starter', 'enjoys', 'working', 'fast-paced,', 'quality-oriented,', 'team', 'environment.', 'You', 'required', 'skills', 'following', 'areas', ':', '6-12', 'years', 'IT', 'experience', '3+', 'years', 'experience', 'writing', 'Machine', 'Learning', 'Algorithms.', 'At', 'least', '5', 'Years', 'experience', 'Python', 'Java', 'services', 'required.', 'A', 'mathematical', 'background', 'experience', 'c', 'lassifications,', 'text', 'processing,', 'image', 'processing', 'deep', 'learning', 'paradigms,', 'semantic', 'analysis,', 'semantic', 'processing', 'unstructured', 'data', 'experience', 'required.', 'Hands-on', 'experience', 'existing', 'Machine', 'Learning', 'Frameworks', '&', 'Libraries', '(keras,', 'spacy,', 'Tensorflow)', 'Experience', 'leading', 'team', 'developers/ML', 'engineers', 'solving', 'delivering', 'solutions.', 'Good', 'understanding', 'data', 'structures,', 'data', 'models', '&', 'software', 'architecture.', 'Experienced', 'working', 'Agile', 'teams.', 'Experience', 'cloud', 'services', '(AWS/Azure/Google).', 'Hands-on', 'experience', 'building/fine-tuning', 'models', 'without', 'leveraging', 'machine', 'learning', 'frameworks.', 'Experience', 'data', 'analytics', 'tools', '(PowerBI,', 'Spotfire,', 'etc)', 'languages', '(Python,', 'R)', 'added', 'advantage.', 'Job', 'Reference', '#', '189404BR', 'City', 'Pune', 'Job', 'Type', 'Full', 'Time', 'Your', 'role', 'Are', 'interested', 'pursuing', 'career', 'Asset', 'Management?', 'Does', 'working', 'data', 'driven', 'business', 'excite', 'you?', 'Do', 'want', 'part', 'data', 'revolution', 'performing', 'hands', 'data', 'analysis', 'developing', 'machine', 'learning', 'models', 'produce', 'working', 'concepts,', 'along', 'managing', 'multiple', 'initiatives', 'cross-functional', 'data', 'analytics', 'needs?', 'We’re', 'looking', 'data', 'scientist', 'to:', 'provide', 'thought', 'leadership', 'predictive', 'modeling', 'machine', 'learning.', 'NLP', 'Deep', 'Learning', 'two', 'focus', 'areas', 'leverage', 'data', 'assets', 'build', 'learning', 'systems', 'predictive', 'models', 'drive', 'efficiency', 'investment', 'process', 'collect,', 'cleanse,', 'massage,', 'organize', 'data', 'deliver', 'actionable', 'insights', 'stakeholders', 'rich', 'visualization', 'presentation', 'deploy', 'models', 'production', 'way', 'easy', 'maintain', 'scalable', 'build', 'infrastructure', 'accelerate', 'pace', 'model', 'exploration', 'improve', 'model', 'serving', 'maintenance', 'manage', 'model', 'release', 'cycle', 'Your', 'team', 'Chief', 'Data', 'Office', '(CDO),', 'within', 'UBS', 'Global', 'Asset', 'Management', '(AM),', 'established', 're-define', 'AM’s', 'data', '&', 'analytics', 'strategy', 'lead', 'innovation', 'agenda', 'division.', 'The', 'CDO', 'provides', 'foundation', 'establishing', 'data', 'analytics', 'driven', 'culture,', 'guiding', 'successful', 'delivery', 'foundational', 'innovative', 'solutions,', 'support', \"AM's\", 'strategic', 'agenda.', 'To', 'design', 'multi-faceted', 'innovative', 'solutions,', 'CDO', 'structured', 'encompass', 'several', 'functions,', 'including', 'Data', 'Analytics,', 'Data', 'Solutions,', 'Data', 'Governance.', 'Analytics', 'Center', 'Excellence', 'team', 'drive', 'Analytics', 'agenda', 'CDO', 'based', 'India', 'Your', 'expertise', 'PhD', 'MS', 'degree', 'Data', 'Science,', 'Operations', 'Research,', 'Applied', 'Math,', 'Statistics,', 'Computer', 'Science,', 'equivalent', 'ideally', '5+', 'years', 'hands-on', 'experience', 'developing', 'statistical', 'models,', 'natural', 'language', 'processing,', 'deep', 'learning', 'models', 'experience', 'machine', 'learning', 'APIs', 'computational', 'packages', 'TensorFlow,', 'Theano,', 'PyTorch,', 'Keras,', 'Scikit-Learn,', 'NumPy,', 'SciPy,', 'Pandas,', 'StatsModels,', 'Spark', 'ML', 'experience', 'time', 'series', 'data', 'models', 'required.', 'experience', 'Big', 'Data', 'technologies', 'Hadoop,', 'Spark,', 'Kubernetes,', 'Kafka,', 'Arrow,', 'demonstrated', 'ability', 'explain', 'present', 'analyses', 'models', 'audiences', 'varying', 'levels', 'expertise', 'demonstrated', 'ability', 'develop', 'production', 'models', 'data', 'pipeline', 'Python', 'experience', 'financial', 'markets', 'time', 'series', 'valuable', 'understanding', 'Agile', 'software', 'methodology', 'fluent', 'English', 'excellent', 'verbal', 'written', 'communication', 'skills.', 'About', 'Us', 'Expert', 'advice.', 'Wealth', 'management.', 'Investment', 'banking.', 'Asset', 'management.', 'Retail', 'banking', 'Switzerland.', 'And', 'support', 'functions.', \"That's\", 'do.', 'And', 'private', 'institutional', 'clients', 'well', 'corporations', 'around', 'world.', 'We', '60,000', 'employees', 'major', 'financial', 'centers,', '50', 'countries.', 'Do', 'want', 'one', 'us?', 'Join', 'us', 'Are', 'truly', 'collaborative?', 'Succeeding', 'UBS', 'means', 'respecting,', 'understanding', 'trusting', 'colleagues', 'clients.', 'Challenging', 'others', 'challenged', 'return.', 'Being', 'passionate', 'do.', 'Driving', 'forward,', 'always', 'wanting', 'things', 'right', 'way.', 'Does', 'sound', 'like', 'you?', 'Then', 'right', 'stuff', 'join', 'us.', 'Apply', 'now.', 'Disclaimer', '/', 'Policy', 'Statements', 'UBS', 'Equal', 'Opportunity', 'Employer.', 'We', 'respect', 'seek', 'empower', 'individual', 'support', 'diverse', 'cultures,', 'perspectives,', 'skills', 'experiences', 'within', 'workforce.', 'Jd', 'Handling', 'business', 'problems', 'come', 'attractive', 'solutions', 'team', 'player', 'Extensively', 'working', 'information', 'extraction', 'NLP', 'Working', 'open', 'source', 'data', 'science', 'technologies', 'Secondary', 'research', 'find', 'apt', 'latest', 'methodology', 'required', 'solve', 'current', 'business', 'problem.', 'Experience', 'general', 'NLP', 'tasks', 'techniques,', 'parsing,', 'text', 'pre-processing,', 'NER,', 'entity', 'linking,', 'relation', 'extraction,', 'etc.', 'Excellent', 'understanding', 'machine', 'learning', 'techniques', 'algorithms,', 'k-NN,', 'Naive', 'Bayes,', 'SVM,', 'Decision', 'Forests,', 'etc.', 'Build', \"POC's\", 'data', 'projects', 'navigate', 'decisions', 'product', 'enhancements', 'Build', 'real-time', 'models', 'leveraging', 'NLP', 'targeted', 'computations', 'Establish', 'machine', 'learning', 'techniques', 'path', 'automating', 'manual', 'workflows', 'Work', 'closely', 'data', 'engineers', 'product', 'teams', 'solve', 'real', 'world', 'problems', 'Hands-on', 'implementation', 'Common', 'data', 'processing', 'technique.', '(ref:hirist.com)', 'Python', 'Developer', 'Job', 'Description', 'Python', 'Developer', 'job', 'description', 'attract', 'experienced', 'developers', 'build', 'functional', 'server-side', 'applications.', 'Python', 'Developer', 'Responsibilities', 'Include', 'Building', 'efficient', 'server-side', 'applications', 'Integrating', 'front-end', 'components', 'applications', 'Checking', 'code', 'developers', 'coaching', 'junior', 'team', 'members', 'Job', 'Brief', 'We', 'looking', 'Python', 'Developer', 'build', 'functional', 'efficient', 'server-side', 'applications.', 'Python', 'Developer', 'responsibilities', 'include', 'participating', 'phases', 'software', 'development', 'lifecycle', 'coaching', 'junior', 'developers.', 'If', 'you-', 'seasoned', 'developer', 'love', 'back-end', 'technologies,', 'we-', 'like', 'meet', 'you.', 'Your', 'ultimate', 'goal', 'create', 'high-quality', 'products', 'meet', 'customer', 'needs.', 'Responsibilities', 'Help', 'design', 'implement', 'functional', 'requirements', 'Build', 'efficient', 'back-end', 'features', 'Python', 'Integrate', 'front-end', 'components', 'applications', 'Manage', 'testing', 'bug', 'fixes', 'Prepare', 'technical', 'documentation', 'Collaborate', 'UX/UI', 'designers', 'implement', 'design', 'code', 'Requirements', '4+', 'Years', 'experience', 'Python', 'Developer', 'Experience', 'Python', 'frameworks', '(e.g.', 'Django,', 'Flask,', 'Sanic,', 'Bottle)', 'Familiarity', 'Amazon', 'Web', 'Services', '(AWS)', 'REST', 'API', 'Worked', 'different', 'databases', 'like', 'MS', 'SQL,', 'MySQL,', 'PostgreSQL,', 'MongoDB.', 'Knowledge', 'JavaScript,', 'Jquery,', 'NodeJS', 'AngularJS', 'framework', 'Skills', 'Machine', 'Learning', 'Python', 'Computer', 'Vision', 'Deep', 'Learning', 'Tensorflow', 'Natural', 'Language', 'Processing', '/', 'Natural', 'Language', 'Understanding', 'Keras', 'Chat', 'Bot', '/', 'Voice', 'Bot', '/', 'Email', 'Bot', 'Development', 'Tools', '&', 'Tech', ':', 'Python,', 'Dialogflow,', 'AWS', 'Cloud,', 'NLP,', 'PostgreSQL,', 'Pandas,', 'AWS', 'Lambda,', 'Docker,', 'Flask,', 'Spacy,', 'BERT,', 'JIRA/', 'Phabricator', '(ref:hirist.com)', 'Experience:', '6', '7.5', 'Years', 'Job', 'Location:Pune', 'Duration', 'Contract', '6', 'Months', 'Notice', 'period', ':only', '15', 'days', 'Python/Machine', 'Learning', 'Web', 'Development', 'mandatory', 'Regards,', 'Jane', 'Masih', '8879389007', 'This', 'job', 'provided', 'Shine.com', 'Description', 'Machine', 'Learning', '(ML)', 'strategic', 'Amazon', 'early', 'years.', 'We', 'pioneers', 'areas', 'recommendation', 'engines,', 'product', 'search,', 'eCommerce', 'fraud', 'detection,', 'large-scale', 'optimization', 'fulfillment', 'center', 'operations.', 'The', 'ML', 'team', 'within', 'Amazon', 'Internet', 'Services', 'Private', 'Limited', '(“AISPL”)', 'provides', 'opportunities', 'innovate', 'fast-paced', 'organization', 'contributes', 'game-changing', 'projects', 'technologies', 'get', 'deployed', 'devices', 'cloud.', 'As', 'Deep', 'Learning', 'Architect', 'AISPL,', 'partner', 'business', 'support', 'teams', 'AISPL', 'build', 'new', 'services', 'surprise', 'delight', 'customers.', 'You', 'working', 'terabytes', 'text,', 'images,', 'types', 'data', 'solve', 'real-world', 'problems.', 'We’re', 'looking', 'top', 'architects,', 'system', 'software', 'engineers', 'AISPL', 'capable', 'using', 'ML', 'techniques', 'design,', 'evangelize,', 'implement', 'state-of-the-art', 'solutions', 'never-before-solved', 'problems.', 'We', 'open', 'locations', 'across', 'India.', 'The', 'Primary', 'Responsibilities', 'Of', 'This', 'Role', 'Are', 'To', 'Use', 'ML', 'tools,', 'Amazon', 'SageMaker', 'Amazon', 'Simple', 'Storage', 'Service,', 'provide', 'scalable', 'cloud', 'environment', 'customers', 'label', 'data,', 'build,', 'train,', 'tune', 'deploy', 'models', 'Collaborate', 'data', 'scientists', 'create', 'scalable', 'ML', 'solutions', 'business', 'problems', 'Interact', 'AISPL', 'customer', 'directly', 'understand', 'business', 'problem,', 'help', 'aid', 'implementation', 'ML', 'ecosystem', 'Analyze', 'extract', 'relevant', 'information', 'large', 'amounts', 'historical', 'data', 'help', 'automate', 'optimize', 'key', 'processes', 'Work', 'closely', 'account', 'team,', 'research', 'scientist', 'teams', 'product', 'engineering', 'teams', 'drive', 'model', 'implementations', 'new', 'algorithms', 'Basic', 'Qualifications', 'BS', 'computer', 'science,', 'related', 'technical,', 'math,', 'scientific', 'field', '7+', 'years', 'professional', 'experience', 'business', 'environment', '5+', 'years', 'relevant', 'experience', 'building', 'large', 'scale', 'enterprise', 'IT', 'systems', '1+', 'year', 'public', 'cloud', 'computing', 'experience', 'AWS', 'Cloud', '1+', 'year', 'experience', 'hosting', 'deploying', 'ML', 'solutions', '(e.g.,', 'training,', 'tuning,', 'inferences)', 'Preferred', 'Qualifications', 'Masters', 'PhD', 'degree', 'computer', 'science,', 'related', 'technical,', 'math,', 'scientific', 'field', 'Strong', 'working', 'knowledge', 'deep', 'learning,', 'machine', 'learning', 'statistics.', 'Hands', 'experience', 'building', 'models', 'deep', 'learning', 'frameworks', 'like', 'MXNet,', 'Tensorflow,', 'Caffe,', 'Torch,', 'Theano', 'similar.', 'Hands', 'experience', 'deep', 'learning', '(e.g.,', 'CNN,', 'RNN,', 'LSTM)', 'Experience', 'using', 'Python,', 'R', 'Matlab', 'statistical/machine', 'learning', 'software', 'Strong', 'communication', 'data', 'presentation', 'skills', 'The', 'motivation', 'achieve', 'results', 'fast-paced', 'environment.', 'Experience', 'statistical', 'modelling', '/', 'machine', 'learning', 'Strong', 'attention', 'detail', 'Comfortable', 'working', 'fast', 'paced,', 'highly', 'collaborative,', 'dynamic', 'work', 'environment', 'Ability', 'think', 'creatively', 'solve', 'problems', 'Company', '-', 'AISPL', '-', 'Maharashtra', 'Job', 'ID:', 'A931543', 'Role', 'Summary/Purpose:', 'Baker', 'Hughes', 'seeks', 'experienced', 'Data', 'Analysts', 'manage', 'perform', 'data', 'cleansing', 'mining', 'duties', 'wireline', 'services', 'product', 'development,', 'geoscience', 'sustaining', 'projects', 'Baker', 'Hughes', 'GEC', 'center', 'Pune.', 'The', 'successful', 'candidate', 'accountable', 'developing', 'delivering', 'conclusions', 'based', 'numbers,', 'trends', 'data', 'types', 'projects', 'executed', 'globally.', 'Essential', 'Responsibilities:', 'Work', 'variety', 'large', 'amount', 'geophysical', 'data', 'cleansing,', 'mining', 'analyzing', 'find', 'conclusions', 'Present', 'findings', 'data', 'translation', 'clear', 'understandable', 'implementation', 'ideas', 'Machine', 'learning', '–', 'building', 'data', 'models', '(neural', 'network,', 'Random', 'Forrest', 'others', 'applicable', 'Math', 'statistics', 'skills', 'needed', 'Knowledge', 'experience', 'deep', 'learning', 'plus', 'Qualifications/Requirements:', 'Bachelor', 'degree', 'field', 'math,', 'statistics', 'computer', 'science', 'recognized', 'university', '3', 'years', 'experience', 'minimum', 'Master’s', 'degree', 'preferred', 'Knowledge', 'upstream', 'Oil', 'Gas', 'industry', 'Experience', 'working', 'wide', 'range', 'stakeholders', 'including', 'operations,', 'sourcing,', 'product', 'management', 'project', 'management', 'organizations', 'Experience', 'working', 'matrix,', 'multicultural', 'environment', 'Desired', 'Characteristics:', 'Python', 'R', 'programming', 'experience', 'portfolio', 'showcase', 'Experience', 'working', 'SAP', 'Clarity', 'desired', 'Excellent', 'written', 'verbal', 'communications', 'skills.', 'Ability', 'work', 'team', 'use', 'initiative', 'Locations:', 'Pune,', 'India', 'This', 'opportunity', 'learn', 'more,', 'more,', 'live', 'career', 'imagined', 'part', 'truly', 'diverse', 'organization.', 'Baker', 'Hughes', 'Equal', 'Opportunity', 'Employer.', 'Employment', 'decisions', 'made', 'without', 'regard', 'race,', 'color,', 'religion,', 'national', 'ethnic', 'origin,', 'sex,', 'sexual', 'orientation,', 'gender', 'identity', 'expression,', 'age,', 'disability,', 'protected', 'veteran', 'status', 'characteristics', 'protected', 'law.', 'Learn', 'Short', 'Description', 'We', 'looking', 'Machine', 'Learning', 'Bigdata', '4', 'Years', '6', 'years', 'Pune.', 'Qualifications', 'B.E/B.Tech/M.E/M.Tech', 'Job', 'Responsibilities', 'We', 'looking', 'hire', 'Machine', 'Learning', 'Bigdata', '4', 'Years', '6', 'years', 'Pune.', 'Role', 'Description', '(Role', '&', 'Responsibilities)', 'Condidate', '4', '6', 'years', 'core', 'experience', 'Machine', 'vision', 'systems', 'Image', 'processing', 'modeling', 'simulation', 'Candidate', '4', '6', 'years', 'core', 'Python', 'R', 'development', 'Experience', 'minimum', 'one', 'year', 'TensorFlow', 'programming', 'Experience', 'maths', 'stats', 'applied', 'Machine', 'Learning', 'algorithms', 'hands', 'applying', 'ML', 'algorithms', 'solution', 'validation', 'Strong', 'programming', 'fundamentals', 'Experience', 'Inferential', 'statistics', 'modeling', 'Exposure', 'database', 'concepts', 'complex', 'SQL', 'queries', 'Exposure', 'standard', 'V', 'V', 'concepts', 'activities', 'configuration', 'management', 'Location:', 'Pune', 'Experience:', '4', '-', '6', 'years', 'Primary', 'Skills', '(Must', 'Have)', 'Machine', 'Learing', 'Algorithms', 'Accenture', 'Technology', 'powers', 'clients’', 'businesses', 'innovative', 'technologies—established', 'emerging—changing', 'way', 'people', 'customers', 'experience', 'work,', 'life', 'entertainment.', 'Join', 'Accenture', 'Technology', 'you’ll', 'translate', 'operational', 'needs', 'world’s', 'governments', 'leading', 'businesses', 'innovative', 'technical', 'solutions', 'enable', 'better', 'serve', 'customers—your', 'friends,', 'family', 'neighbors.You’ll', 'deliver', 'everything', 'point', 'solutions', 'single', 'business', 'function', 'large,', 'long-term', 'outsourcing', 'services,', 'complex', 'systems', 'integration', 'installations', 'spanning', 'multiple', 'businesses', 'functions.', 'You’ll', 'create', 'custom-designed', 'solutions', 'integrate', 'technology', 'platforms', 'operations.', 'Role', ':Application', 'Developer', 'Role', 'Description', ':Design,', 'build', 'configure', 'applications', 'meet', 'business', 'process', 'application', 'requirements.', 'Must', 'Have', 'Skills', ':Computer', 'Vision,TensorFlow', 'Good', 'To', 'Have', 'Skills', ':', 'Job', 'Requirements', ':', '1:Responsibilities', 'A:Methods', 'acquiring,processing,analyzing', 'understing', 'digital', 'images', 'B:Develop', 'algorithms', 'applications', 'related', 'image', 'video', 'processing', 'perform', 'functions', 'object', 'identification', 'classification', 'C:Review', 'integrate', 'application', 'requirements,including', 'functional,security,integration,performance,quality', 'operations', 'requirements', 'Review', 'integrate', 'Technical', 'Architecture', 'requirements', 'Provide', 'input', 'final', 'decisions', 'regarding', 'hardware,network', 'products,system', 'software', 'security', '2:Professional', 'Experience', 'Must', 'Skills', ':', 'A:Machine', 'learning', 'exposure', 'B:Deep', 'learning/Google', 'TensorFlow/Python', 'Machine', 'Learning', 'eg', 'scikit-learn', 'Good', 'Have:', 'A:Open', 'source', 'ML', 'libraries', 'tools', 'like', 'Apache', 'Mahout,Apache', 'Spark', '15', 'years', 'full', 'time', 'education', 'Manager', '/', 'Senior', 'ManagerPOSITION', 'TITLE:', 'Marketing', 'Customer', 'AnalyticsROLE', '&', 'RESPONSIBILITIES', 'As', 'part', 'Marketing', '&', 'Customer', 'Analytics', 'team', 'primary', 'responsibility', 'support', 'Marketing', 'team', 'provide', 'actionable', 'insights', 'measure,', 'manage', 'analyze', 'marketing', 'related', 'activities.', 'In', 'role', 'required', 'analysis', 'solving', 'moderate', 'complex', 'marketing', 'analytics', 'problem.', 'You', 'would', 'single', 'point', 'contact', 'Campaign', 'Analytics', 'related', 'activities,', 'provide', 'recommendations', 'marketing', 'team', 'analyze', 'effectiveness', 'marketing', 'campaigns', 'using', 'ROI', 'calculations.', 'Understanding', 'Customer', 'behavior', 'segment', 'customers', 'based', 'available', 'data', 'points', 'marketing', 'team', 'target', 'right', 'set', 'customers.', 'The', 'person', 'generally,', 'interacts', 'senior', 'management', 'leadership', 'levels,', 'requires', 'understanding', 'strategic', 'direction', 'set', 'senior', 'management.', 'The', 'person', 'typically', 'able', 'create', 'new', 'solutions', 'strategy', 'leveraging', 'data', 'without', 'adapting', 'existing', 'methods', 'procedures.', 'Should', 'able', 'work', 'independently', 'require', 'minimal', 'guidance', 'working', 'new', 'projects', 'problems.', 'The', 'successful', 'candidate', 'responsible', 'developing,', 'analyzing', 'executing', 'ideas', 'initiatives', 'designed', 'achieve', 'business', 'growth', 'loss', 'mitigation', 'goals.', 'Other', 'requirements', 'follows', '-', 'Look', 'providing', 'solutions', 'go', 'beyond', 'traditional', 'methods', 'Using', 'advanced', 'machine', 'learning', 'technologies', 'new', 'data', 'sources.', 'Develop', 'next-gen', 'modeling', 'capabilities', 'deliver', 'best', 'class', 'predictive', 'modeling', 'solutions.', 'Should', 'hands', 'experience', 'marketing', 'analytics', 'solution', 'using', 'machine', 'learning', 'algorithm.', 'Has', 'worked', 'projects', 'involving', 'large', 'datasets', 'running', 'TBs,', 'structured', 'unstructured', 'datasets', 'Independently', 'manage', 'development', 'implementation', 'effective', 'marketing', 'mix', 'strategies', 'help', 'reduce', 'cost', 'acquisition', 'organization.-', 'Liaising', 'internally', 'business', 'stakeholders,', 'including', 'explaining', 'model', 'outputs,', 'performing', 'ad-hoc', 'analysis', 'answering', 'technical', 'background', 'questions', 'models', 'requirements.', 'To', 'define,', 'analyze,', 'implement,', 'monitor', 'marketing', 'strategies.', 'Must', 'capability', 'clearly', 'communicate', 'analysis', 'Must', 'able', 'effectively', 'provide', 'updates', 'communicate', 'key', 'initiatives', 'senior', 'managementTechnical', 'capability', 'Hands', 'experience', 'SQL', '(or', 'similar', 'structured', 'non-structured', 'database).', 'Hands', 'experience', 'Tableau', '(or', 'similar', 'tools).', '(ref:iimjobs.com)', 'Responsibilities', 'Model', 'problem', 'DL', 'framework', 'Build,', 'measure', 'iterate', 'neural', 'network', 'architectures', 'effectively', 'solve', 'problem', 'Benchmark,', 'validate', 'test', 'solution', 'real-world', 'environments', 'Optimise', 'solution', 'accuracy', 'performance', 'Requirements', 'Skill(s)', 'required:', 'Experience', 'wirh', 'Deep', 'Learning', 'Programming.', 'Have', 'relevant', 'skills', 'interests', 'Have', 'prior', 'knowledge', 'experience', 'Deep', 'Learning', 'image/video', 'related', 'problems', 'Good', 'have:', 'hands-on', 'experience', 'Tensorflow', 'Python', 'Has', 'done', 'Deep', 'Learning', 'courses,', 'perhaps', 'MOOCs', 'Coursera,', 'Udacity,', 'etc', 'Company', 'Name:', 'MarketsandMarkets', 'Company', 'Website:', 'www.marketsandmarkets.com', 'Job', 'Location:', 'This', 'full', 'time', 'role', 'based', 'HO', 'Pune', 'Designation:', 'Vice', 'President', 'Product', 'Development', 'Our', 'Product', 'Brief', '•', 'Our', 'aim', 'disrupt', 'current', 'market', 'leader', 'technology', 'research—a', 'three-billion-dollar', 'company.', '•', 'The', 'aforementioned', 'market', 'leader’s', 'flagship', 'product', 'limited', 'breadth', 'depth,', 'biased,', 'transparent,', 'scalable,', 'less', 'insightful', 'improving', 'ratings.', '•', 'The', 'company', 'conforms', 'ideology', 'one', 'solution', 'fits', 'all;', 'unfeasible', 'outlook', 'today’s', 'market', 'conditions.', '•', 'Our', 'product/platform', 'aims', 'provide', 'actionable', 'insights', 'enable', 'B2B', 'provider-side', 'companies', 'improve', 'ratings', 'market', 'position', 'well', 'buyer-side', 'companies', 'benchmark', 'best', 'providers.', 'Our', 'product', 'dual', 'IP,', 'research', 'repository', 'technology', 'already', 'built', 'in.', 'It', 'technology', 'stack', 'comprising', 'machine', 'learning,', 'big', 'data,', 'cognitive', 'computing.', 'By', 'leveraging', 'proprietary', 'research,', 'platform', 'well', 'poised', 'meaningfully', 'triangulate', 'public', 'data,', 'enterprise', 'data,', 'proprietary', 'data.', '•', 'The', 'platform', 'utilize', 'multidimensional', 'hierarchical', 'approach', 'capture', 'insights', 'accurately', 'analyze', 'available', 'data', 'ascertain', 'best', 'providers.', '•', 'The', 'platform', 'also', 'use', 'digitalized', 'approach', 'capture', 'strengths', 'weaknesses', 'dynamic', 'rating', 'mechanism', 'deep', 'dive', 'critical', 'capabilities', '10,000', 'technologies', '(quadrants)', 'across', 'multiple', 'industries.', '•', 'The', 'platform', 'potential', 'evolve', 'first-of-its-kind', 'marketplace', '$3.7', 'trillion', 'global', 'tech', 'spend.', '•', 'The', 'platform', 'nearing', 'completion', 'technology', 'standpoint,', 'renewed', 'UX-UI,', 'almost', 'ready', 'market', 'launch.', 'Role', 'Expectation', 'You', 'shall', 'responsible', 'successful', 'commercialization', 'go-to', 'market', 'product/platform', 'well', 'optimization', 'best', 'suit', 'needs', 'target', 'audience.', 'You', 'shall', 'also', 'responsible', 'achieving', 'strategic,', 'financial,', 'technical,', 'operational', 'goals', 'pertaining', 'product.', 'As', 'part', 'role,', 'shall', 'required', 'strategize', 'execute', 'robust', 'milestone-based', 'plan.', 'The', 'product,', 'extremely', 'disruptive,', 'needs', 'aggressive', 'execution', 'reach', 'high', 'acceptance', 'goes', 'viral.', 'To', 'end,', 'may', 'necessary', 'trade-off', 'available', 'resources,', 'infrastructure,', 'technology', 'prioritize', 'certain', 'aspects', 'product', 'launch', 'strategy.', 'Over', '95,000', 'B2B', 'companies', 'approached', 'us;', '7,500', 'clients', 'worldwide', 'including', '80%', 'Forbes', 'Global', '2000', 'companies.', 'You', 'choose', 'multiple', 'ways', 'bring', 'product', 'market,', 'including', 'leveraging', 'existing', 'client', 'base.', 'Other', 'expectations', 'would', 'include:', '1.', 'For', 'maximum', 'effectiveness,', 'would', 'crucial', 'meet', 'vendor-side', 'buyer-side', 'expectations', 'lure', 'platform.', '2.', 'It', 'would', 'imperative', 'trade-off', 'building', 'enough', 'critical', 'mass', 'minimal', 'viable', 'product', 'providing', 'world-class', 'experience', 'bells', 'whistles.', '3.', 'It', 'would', 'also', 'important', 'trade-off', 'already', 'built', 'versus', 'full-fledged', 'product', 'meeting', 'clients’', 'expectations,', 'keeping', 'end', 'goal', 'going', 'market', 'quicker', 'mind.', 'You', '15+', 'years', 'previous', 'experience', 'developing', 'large', 'successful', 'product-driven', 'business', 'model', 'alongside', 'building', 'end-to-end', 'digitalized', 'client', 'engagement', 'client', 'acquisition', 'post-sale', 'engagement.', 'Experience', 'big', 'data,', 'machine', 'learning,', 'data', 'crowdsourcing,', 'cognitive', 'computing', 'preferred.', 'A', 'detailed', 'understanding', 'technology', 'would', 'add-on.', 'Technology', 'Support', 'Operations-', 'Specialist', 'IN-Pune', 'FICO', '(NYSE:', 'FICO)', 'leading', 'global', 'analytics', 'software', 'company,', 'helping', 'businesses', '90+', 'countries', 'make', 'better', 'decisions.', 'Join', 'world-class', 'team', 'today', 'fulfill', 'career', 'potential!', 'Job', 'Summary', 'Pune', 'NOC', 'L1', 'engineer', 'support', 'candidate', 'needed', 'Linux', 'knowledge', 'fluent', 'communication.', 'Job', 'Description', 'Position', 'Title', ':', 'Technology', 'Support', 'Operations', 'Engineer', 'I', 'About', 'FICO', 'FICO', '(NYSE:', 'FICO)', 'leading', 'analytics', 'software', 'company,', 'helping', 'businesses', '90+', 'countries', 'make', 'better', 'decisions', 'drive', 'higher', 'levels', 'growth,', 'profitability', 'customer', 'satisfaction.', 'The', 'company’s', 'groundbreaking', 'use', 'Big', 'Data', 'mathematical', 'algorithms', 'predict', 'consumer', 'behavior', 'transformed', 'entire', 'industries.', 'FICO', 'provides', 'analytics', 'software', 'tools', 'used', 'across', 'multiple', 'industries', 'manage', 'risk,', 'fight', 'fraud,', 'build', 'profitable', 'customer', 'relationships,', 'optimize', 'operations', 'meet', 'strict', 'government', 'regulations.', 'Many', 'products', 'reach', 'industry-wide', 'adoption', '—', 'FICO®', 'Score,', 'standard', 'measure', 'consumer', 'credit', 'risk', 'United', 'States.', 'FICO', 'solutions', 'leverage', 'open-source', 'standards', 'cloud', 'computing', 'maximize', 'flexibility,', 'speed', 'deployment', 'reduce', 'costs.', 'The', 'company', 'also', 'helps', 'millions', 'people', 'manage', 'personal', 'credit', 'health.', 'FICO:', 'Make', 'every', 'decision', 'count™.', 'Founded', '1956,', 'FICO', 'introduced', 'analytic', 'solutions', 'credit', 'scoring', 'made', 'credit', 'widely', 'available,', 'United', 'States', 'around', 'world.', 'We', 'pioneered', 'development', 'application', 'critical', 'technologies', 'behind', 'decision', 'management.', 'These', 'include', 'predictive', 'analytics,', 'business', 'rules', 'management', 'optimization.', 'We', 'use', 'technologies', 'help', 'businesses', 'improve', 'precision,', 'consistency', 'agility', 'complex,', 'high–volume', 'decisions.', 'Skills', 'Required', 'Experience', 'providing', 'application', 'support', 'Linux/Unix', 'environment', 'Experience', 'MySQL', 'database', 'Should', 'well', 'versed', 'change', 'incident', 'management', 'skills', 'Open', 'work', '24', '*', '7', 'environment', 'Good', 'Communication', 'skills', 'Why', 'Make', 'Move', 'FICO?', 'At', 'FICO,', 'develop', 'career', 'leading', 'organization', 'one', 'fastest-growing', 'fields', 'technology', 'today', '–', 'Big', 'Data', 'analytics.', 'You’ll', 'play', 'part', 'commitment', 'help', 'businesses', 'use', 'data', 'improve', 'every', 'choice', 'make,', 'using', 'advances', 'artificial', 'intelligence,', 'machine', 'learning,', 'predictive', 'prescriptive', 'modeling,', 'much', 'more.', 'FICO', 'makes', 'real', 'difference', 'way', 'businesses', 'operate', 'worldwide:', 'Credit', 'Scoring', '—', '150+', 'billion', 'FICO', 'Scores', 'sold', 'date,', 'making', 'used', 'credit', 'score', 'world.', 'Fraud', 'Detection', 'Security', '—', '2.6+', 'billion', 'payment', 'cards', 'globally', 'protected', 'FICO', 'fraud', 'systems.', 'Lending', '—', '3/4', 'US', 'mortgages', 'approved', 'using', 'FICO', 'Score.', 'Anti-Money', 'Laundering', '—', 'solutions', 'check', 'half', 'billion', 'transactions', 'day', 'prevent', 'criminal', 'schemes', 'terrorist', 'financing', 'Global', 'trends', 'toward', 'digital', 'transformation', 'created', 'tremendous', 'demand', 'FICO’s', 'solutions,', 'placing', 'us', 'among', 'world’s', 'top', '100', 'software', 'companies', 'revenue.', 'We', 'support', 'many', 'world’s', 'largest', 'banks,', 'insurers,', 'retailers,', 'telecommunications', 'providers', 'firms', 'reach', 'new', 'level', 'success.', 'Our', 'success', 'dependent', 'really', 'talented', 'people', '–', 'like', 'you–', 'thrive', 'collaboration', 'innovation', 'that’s', 'nurtured', 'diverse', 'inclusive', 'environment.', 'We’ll', 'provide', 'support', 'need,', 'ensuring', 'freedom', 'develop', 'skills', 'grow', 'career.', 'Join', 'FICO', 'help', 'change', 'way', 'business', 'thinks!', 'Learn', 'fulfill', 'potential', 'www.fico.com/Careers', 'FICO', 'values', 'benefit', 'diversity', 'culture', 'inclusion', 'bring', 'workplace.', 'We', 'equal', 'employment', 'opportunity', 'affirmative', 'action', 'employer', 'we’re', 'proud', 'offer', 'employment', 'advancement', 'opportunities', 'applicants', 'without', 'regard', 'race,', 'color,', 'ancestry,', 'religion,', 'sex,', 'national', 'origin,', 'pregnancy,', 'sexual', 'orientation,', 'age,', 'citizenship,', 'marital', 'status,', 'disability,', 'gender', 'identity', 'Veteran', 'status.', 'Posted', '12', 'Days', 'Ago', 'Full', 'time', '22667', 'FICO', '(NYSE:', 'FICO)', 'leading', 'global', 'analytics', 'software', 'company,', 'supporting', 'businesses', '90+', 'countries', 'make', 'better', 'decisions.', 'Join', 'world-class', 'team', 'today', 'fulfill', 'career', 'potential!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyHTgSMXJCgy",
        "colab_type": "code",
        "outputId": "55f9f130-e619-4434-ee34-faed38152054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        " nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRIPs4shJCg1",
        "colab_type": "code",
        "outputId": "d6966b8f-fcab-41c1-8eac-225d863515a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import nltk\n",
        "tagged = nltk.pos_tag(filtered_sentence)\n",
        "#print(tagged)\n",
        "\n",
        "a=[]\n",
        "\n",
        "for item in tagged:\n",
        "    if item[:][1]==\"NNP\":\n",
        "        a.append(item[0])\n",
        "#print(a)\n",
        "\n",
        "a = [key.capitalize() for key in a]\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Implementation', 'Development', 'Cnn', 'Rnn.', 'Developing', 'Implementing', 'Mentoring', 'Associates', 'Establish', 'Contributing', 'Requirements', 'Min', 'Strong', 'Regression', 'Logistic', 'Regression/decision', 'Tree,', 'Time', 'Support', 'Vector', 'Machine,', 'Neural', 'Network', 'Proficient', 'Python', 'Flow', 'Keras).', 'Strong', 'Good', 'Machine', 'Learning/', 'Data', 'Scientist', 'Job', 'Requirements', 'Minimum', 'Machine', 'Learning', 'Expert', 'Ml', 'Ml', 'Apply', 'Understanding', 'Natural', 'Language', 'Processing', 'Conceptual', 'Proficiency', 'Python', 'Sas).', 'Extensive', 'Analysis,', 'Reduced', 'Dimensional', 'Data', 'Representations', 'Multi-scale', 'Feature', 'Identification).', 'Research', 'Good', 'Nosql', 'Db', '(mongo/casandra)', '(ref:www.freshersworld.com,freshersworld)', 'Machine', 'Learning', 'Associatesyou', 'Ml', '/', 'Ai', '/', 'Nlp', 'Logistic', 'Regression,', 'Decision', 'Trees', 'Random', 'Forest', 'Ensemble.', 'Core', 'Java', '/', 'Java', 'Ee,', 'R', 'Python.', 'Ml', 'Shine.com', 'Are', 'Ai', 'Helpshift.', 'Ai', 'Python,', 'Apis,', 'Kafka', '(on', 'Aws', 'Azure),', 'Ai', 'San', 'Francisco', 'Pune,', 'India.', 'Pune', 'Ai', 'Think', 'Mle', '\"ml', 'Ml', 'Apis,', 'Kafka', '(on', 'Aws', 'Azure),', 'Productionizing', 'Expect', 'However,', 'Agile', 'How', 'Big', 'Helpshift', 'Helpshift', '~400gb', 'Vms', 'Proficiency', 'Python', 'Understanding', 'Web', 'Data', 'Predictive', 'Machine', 'Fraud', 'Shine.com', 'Responsibilities', 'Work', 'Work', 'Study', 'Apply', 'Use', 'Requirements', 'Strong', 'Ability', 'Proficiency', 'Sql,', 'Python,', 'R.', \"Master's\", 'Degree', 'Statistics,', 'Mathematics,', 'Econometrics,', 'Operations', 'Research,', 'Computer', 'Science,', 'Physics', 'Expertise', 'Must', 'Solid', 'Experience', 'Demonstrated', 'Familiarity', 'Git),', 'Aws.', 'Knowledge', 'Do', 'Aera', 'Technology,', 'Think', 'Self-driving', 'Enterprise™.', 'Aera', 'Aera', 'Technology', 'Machine', 'Learning', 'Engineer', 'Pune', 'Aera', 'Engineering', 'Data', 'Science', 'Data', 'Science,', 'Engineering', 'Devops', 'Design', 'Machine', 'Learning', 'Building', 'Computer', 'Science/computer', 'Engineering', 'Machine', 'Learning', 'Strong', 'Python', 'Experience', 'Apache', 'Spark', 'Experience', 'Machine', 'Learning', 'Experience', 'Spark,', 'Hadoop,', 'Kafka', 'Take', 'Machine', 'Learning', 'Experience', 'Data', 'Ml', 'Pipelines', 'Ml', 'Mlflow,', 'Data', 'Version', 'Control', 'Experience', 'Docker', 'Kubernetes', 'Experience', 'Agile', 'Methodology,', 'Ci/cd,', 'Jenkins,', 'Git', 'Jira', 'Should', 'Aws', 'Linux', 'Spark', 'Python', 'Aera,', 'Self-driving', 'Enterprise:', 'Headquartered', 'Mountain', 'View,', 'California,', 'Mountain', 'View', 'San', 'Francisco', '(california),', 'Bucharest', 'Cluj-napoca', '(romania),', 'Paris', '(france),', 'Munich', '(germany),', 'London', '(uk),', 'Pune', '(india),', 'Sydney', '(australia).', 'So', 'Yash', 'Technologies,', 'Machine', 'Learning', 'It', 'Machine', 'Learning', 'Algorithms.', 'Python', 'Java', 'Hands-on', 'Machine', 'Learning', 'Frameworks', 'Libraries', '(keras,', 'Tensorflow)', 'Experience', 'Experienced', 'Agile', 'Experience', 'Experience', 'Spotfire,', '(python,', 'R)', 'Job', 'Reference', 'City', 'Pune', 'Job', 'Type', 'Full', 'Time', 'Are', 'Asset', 'Management?', 'Does', 'We’re', 'Nlp', 'Deep', 'Learning', 'Your', 'Chief', 'Data', 'Office', '(cdo),', 'Ubs', 'Global', 'Asset', 'Management', '(am),', 'Am’s', 'Cdo', \"Am's\", 'Cdo', 'Data', 'Analytics,', 'Data', 'Solutions,', 'Data', 'Governance.', 'Analytics', 'Center', 'Excellence', 'Cdo', 'India', 'Your', 'Phd', 'Ms', 'Data', 'Science,', 'Operations', 'Research,', 'Applied', 'Math,', 'Statistics,', 'Computer', 'Science,', 'Apis', 'Tensorflow,', 'Theano,', 'Pytorch,', 'Keras,', 'Scikit-learn,', 'Numpy,', 'Scipy,', 'Pandas,', 'Statsmodels,', 'Spark', 'Ml', 'Big', 'Data', 'Hadoop,', 'Spark,', 'Kubernetes,', 'Kafka,', 'Arrow,', 'Python', 'Agile', 'English', 'Us', 'Expert', 'Wealth', 'Investment', 'Asset', 'Retail', 'Switzerland.', \"That's\", 'Do', 'Join', 'Ubs', 'Being', 'Driving', 'Does', 'Apply', 'Disclaimer', 'Policy', 'Statements', 'Ubs', 'Equal', 'Opportunity', 'Employer.', 'Jd', 'Handling', 'Nlp', 'Working', 'Secondary', 'Experience', 'Nlp', 'Ner,', 'Naive', 'Bayes,', 'Svm,', 'Decision', 'Forests,', 'Build', \"Poc's\", 'Nlp', 'Common', '(ref:hirist.com)', 'Python', 'Developer', 'Job', 'Description', 'Python', 'Developer', 'Python', 'Developer', 'Responsibilities', 'Include', 'Building', 'Job', 'Brief', 'Python', 'Developer', 'Python', 'Developer', 'Responsibilities', 'Help', 'Python', 'Integrate', 'Prepare', 'Collaborate', 'Ux/ui', 'Python', 'Developer', 'Experience', 'Python', '(e.g.', 'Django,', 'Flask,', 'Sanic,', 'Bottle)', 'Familiarity', 'Amazon', 'Web', '(aws)', 'Rest', 'Api', 'Worked', 'Ms', 'Sql,', 'Mysql,', 'Postgresql,', 'Mongodb.', 'Knowledge', 'Javascript,', 'Jquery,', 'Nodejs', 'Angularjs', 'Skills', 'Machine', 'Learning', 'Python', 'Computer', 'Vision', 'Deep', 'Learning', 'Tensorflow', 'Natural', 'Language', 'Processing', '/', 'Natural', 'Language', 'Understanding', 'Keras', 'Chat', 'Bot', '/', 'Voice', 'Bot', '/', 'Email', 'Bot', 'Development', 'Tools', 'Tech', 'Python,', 'Dialogflow,', 'Aws', 'Cloud,', 'Nlp,', 'Postgresql,', 'Pandas,', 'Aws', 'Lambda,', 'Docker,', 'Flask,', 'Spacy,', 'Bert,', 'Jira/', 'Phabricator', '(ref:hirist.com)', 'Experience:', 'Job', 'Location:pune', 'Duration', 'Contract', 'Months', 'Notice', 'Python/machine', 'Learning', 'Web', 'Development', 'Regards,', 'Jane', 'Masih', 'Shine.com', 'Description', 'Machine', 'Learning', '(ml)', 'Amazon', 'Ml', 'Amazon', 'Internet', 'Services', 'Private', 'Limited', '(“aispl”)', 'Deep', 'Learning', 'Architect', 'Aispl,', 'Aispl', 'We’re', 'Aispl', 'Ml', 'India.', 'Primary', 'Role', 'Are', 'Use', 'Ml', 'Amazon', 'Sagemaker', 'Amazon', 'Simple', 'Storage', 'Service,', 'Collaborate', 'Ml', 'Interact', 'Aispl', 'Ml', 'Analyze', 'Basic', 'Qualifications', 'Bs', 'It', 'Aws', 'Cloud', 'Ml', 'Preferred', 'Qualifications', 'Masters', 'Phd', 'Strong', 'Hands', 'Mxnet,', 'Tensorflow,', 'Caffe,', 'Torch,', 'Theano', 'Hands', 'Cnn,', 'Rnn,', 'Lstm)', 'Experience', 'Python,', 'R', 'Matlab', 'Strong', 'Experience', 'Comfortable', 'Ability', 'Company', 'Aispl', 'Maharashtra', 'Job', 'Id:', 'A931543', 'Role', 'Summary/purpose:', 'Baker', 'Hughes', 'Data', 'Baker', 'Hughes', 'Gec', 'Pune.', 'Essential', 'Responsibilities:', 'Work', 'Machine', 'Random', 'Forrest', 'Math', 'Knowledge', 'Qualifications/requirements:', 'Bachelor', 'Master’s', 'Knowledge', 'Oil', 'Gas', 'Experience', 'Experience', 'Desired', 'Characteristics:', 'Python', 'R', 'Experience', 'Sap', 'Clarity', 'Excellent', 'Ability', 'Locations:', 'Pune,', 'India', 'Baker', 'Hughes', 'Equal', 'Opportunity', 'Employer.', 'Employment', 'Learn', 'Short', 'Description', 'Machine', 'Learning', 'Bigdata', 'Pune.', 'Qualifications', 'B.e/b.tech/m.e/m.tech', 'Job', 'Responsibilities', 'Machine', 'Learning', 'Bigdata', 'Pune.', 'Role', 'Description', '(role', 'Responsibilities)', 'Condidate', 'Machine', 'Image', 'Candidate', 'Python', 'R', 'Experience', 'Tensorflow', 'Experience', 'Machine', 'Learning', 'Ml', 'Strong', 'Experience', 'Inferential', 'Exposure', 'Sql', 'Exposure', 'V', 'V', 'Location:', 'Pune', 'Experience:', 'Primary', 'Skills', '(must', 'Have)', 'Machine', 'Learing', 'Algorithms', 'Accenture', 'Technology', 'Join', 'Accenture', 'Technology', 'You’ll', 'Role', ':application', 'Developer', 'Role', 'Description', ':design,', 'Must', 'Have', 'Skills', ':computer', 'Vision,tensorflow', 'Good', 'B:develop', 'C:review', 'Review', 'Technical', 'Architecture', 'Provide', 'Must', 'Skills', 'A:machine', 'B:deep', 'Tensorflow/python', 'Machine', 'Learning', 'Good', 'Have:', 'A:open', 'Ml', 'Apache', 'Mahout,apache', 'Spark', 'Manager', '/', 'Senior', 'Managerposition', 'Title:', 'Marketing', 'Customer', 'Analyticsrole', 'Responsibilities', 'Marketing', 'Customer', 'Analytics', 'Marketing', 'Campaign', 'Analytics', 'Roi', 'Customer', 'Should', 'Develop', 'Should', 'Has', 'Tbs,', 'Liaising', 'Must', 'Must', 'Hands', 'Sql', '(or', 'Hands', 'Tableau', '(or', 'Responsibilities', 'Model', 'Dl', 'Build,', 'Benchmark,', 'Optimise', 'Requirements', 'Skill(s)', 'Experience', 'Deep', 'Learning', 'Programming.', 'Have', 'Deep', 'Learning', 'Tensorflow', 'Python', 'Has', 'Deep', 'Learning', 'Moocs', 'Coursera,', 'Udacity,', 'Company', 'Name:', 'Marketsandmarkets', 'Company', 'Website:', 'Job', 'Location:', 'Ho', 'Pune', 'Designation:', 'Vice', 'President', 'Product', 'Development', 'Brief', '•', '•', 'B2b', 'Ip,', '$3.7', 'Ux-ui,', 'Role', 'Expectation', 'B2b', 'Forbes', 'Global', 'Experience', 'A', 'Technology', 'Support', 'Operations-', 'Specialist', 'In-pune', 'Fico', '(nyse:', 'Fico)', 'Join', 'Job', 'Summary', 'Pune', 'Noc', 'L1', 'Linux', 'Job', 'Description', 'Position', 'Title', 'Support', 'Operations', 'Engineer', 'Fico', 'Fico', '(nyse:', 'Fico)', 'Big', 'Data', 'Fico', '—', 'Fico®', 'Score,', 'United', 'States.', 'Fico', 'Fico:', 'Make', 'Fico', 'United', 'Skills', 'Required', 'Experience', 'Linux/unix', 'Experience', 'Mysql', 'Should', 'Open', 'Good', 'Communication', 'Make', 'Fico?', 'Fico,', '–', 'Big', 'Data', 'You’ll', 'Fico', 'Credit', 'Scoring', 'Fico', 'Scores', 'Fraud', 'Detection', 'Security', 'Fico', 'Lending', 'Us', 'Fico', 'Score.', 'Anti-money', 'Laundering', '—', 'Global', 'Fico’s', 'We’ll', 'Join', 'Fico', 'Learn', 'Fico', 'Veteran', 'Ago', 'Full', 'Fico', '(nyse:', 'Fico)', 'Join']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr3HhreTzaBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use to import pandas\n",
        "import pandas as pd\n",
        "#Use to import the file into google Colab drive\n",
        "from google.colab import files \n",
        "#Use to import io, which opens the file from the Colab drive\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q06uZlMGzbtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This will open a widget when run that will enable you to browse the files on your local storage drive.\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZQsrGplmhIb",
        "colab_type": "code",
        "outputId": "13872839-57ca-493a-ab79-db4cea3b5499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df = pd.read_excel('Book1.xlsx')\n",
        "#print(df)\n",
        "Custom_data=df.iloc[:,0].tolist()\n",
        "#print(Custom_data)\n",
        "#Capitalizing custom data\n",
        "Custom_data = [word.capitalize() for word in Custom_data]\n",
        "print(Custom_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Tensorflow', 'C++', 'Deep learning', 'Machine learning', 'Mysql', 'Mongodb', 'Aws', 'Azure', 'R', 'Nlp', 'Nvidia', 'Sklearn', 'Svm', 'Random forests', 'Naïve bayes', 'Data science', 'Ai', 'Data science', 'Cnn', 'Rnn', 'Logistic regression', 'Deep learning', 'Data mining', 'Keras', 'Decision tree', 'Python', 'Casandra', 'Flask', 'Spark', 'Hadoop', 'Jira', 'Scikit-learn', 'Numpy', 'Pandas', 'Scipy', 'Kubernetes', 'K-nn', 'Javascript', 'Jquery', 'Nodejs', 'Angularjs', 'Spacy', 'Lstm', 'Big data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH0yhBrvTbnw",
        "colab_type": "code",
        "outputId": "8e8a8652-a664-4bcc-97d5-dd7daa3b286b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.tokens import Span\n",
        "\n",
        "class EntityMatcher(object):\n",
        "    name = \"entity_matcher\"\n",
        "\n",
        "    def __init__(self, nlp, terms, label):\n",
        "        patterns = [nlp.make_doc(text) for text in terms]\n",
        "        self.matcher = PhraseMatcher(nlp.vocab)\n",
        "        self.matcher.add(label, None, *patterns)\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        matches = self.matcher(doc)\n",
        "        for match_id, start, end in matches:\n",
        "            span = Span(doc, start, end, label=match_id)\n",
        "            doc.ents = list(doc.ents) + [span]\n",
        "        return doc\n",
        "\n",
        "nlp = spacy.blank('en')\n",
        "#terms = (\"Tensorflow\", \"NLP\", \"MongoDB\", \"MySQL\",\"NVIDIA\",\"Machine Learning\")\n",
        "entity_matcher = EntityMatcher(nlp, Custom_data, \"Technology\")\n",
        "\n",
        "nlp.add_pipe(entity_matcher)\n",
        "\n",
        "#print(nlp.pipe_names)  # The components in the pipeline\n",
        "doc = \" \"\n",
        "for words in a:\n",
        "  doc = doc +\" \"+words\n",
        "doc1 = nlp(doc)\n",
        "#print(doc1)\n",
        "#doc = nlp(\"We provide technologies Machine \")\n",
        "#print([(ent.text, ent.label_) for ent in doc1.ents])\n",
        "l2 =[]\n",
        "for ent in doc1.ents:\n",
        "  l2.append(ent.text)\n",
        "print(l2)\n",
        "  \n",
        "#for word in doc1.ents:\n",
        "#  l=str(word)\n",
        "#  s=list2.append(l)\n",
        "\n",
        "#print(s)\n",
        "#import itertools\n",
        "#out = list(itertools.chain(*(doc1.ent)))\n",
        "\n",
        "#print(out) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Cnn', 'Rnn', 'Python', 'Keras', 'Python', 'Ai', 'Nlp', 'R', 'Python', 'Ai', 'Ai', 'Python', 'Aws', 'Azure', 'Ai', 'Ai', 'Aws', 'Azure', 'Python', 'Python', 'Aws', 'Python', 'Spark', 'Spark', 'Hadoop', 'Kubernetes', 'Jira', 'Aws', 'Spark', 'Python', 'Python', 'Tensorflow', 'R', 'Nlp', 'Tensorflow', 'Keras', 'Scikit-learn', 'Numpy', 'Scipy', 'Pandas', 'Spark', 'Hadoop', 'Spark', 'Kubernetes', 'Python', 'Nlp', 'Nlp', 'Svm', 'Nlp', 'Python', 'Python', 'Python', 'Python', 'Python', 'Python', 'Python', 'Python', 'Flask', 'Mysql', 'Mongodb', 'Javascript', 'Jquery', 'Nodejs', 'Angularjs', 'Python', 'Tensorflow', 'Keras', 'Python', 'Aws', 'Nlp', 'Pandas', 'Aws', 'Flask', 'Spacy', 'Python', 'Aws', 'Tensorflow', 'Cnn', 'Rnn', 'Lstm', 'Python', 'R', 'Python', 'R', 'Python', 'R', 'Tensorflow', 'Tensorflow', 'Spark', 'Tensorflow', 'Python', 'Mysql']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyWcGJMOTb3G",
        "colab_type": "code",
        "outputId": "2f201901-7e0a-41d0-9474-42c6bd29ff7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "from  collections import Counter\n",
        "counts = Counter(l2)\n",
        "counts.most_common()\n",
        "#print(counts)\n",
        "df = pd.DataFrame.from_dict(counts, orient='index').reset_index()\n",
        "df.rename(columns={ df.columns[1]: \"freq\" }, inplace = True)\n",
        "df.sort_values(by=[\"freq\"],ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Python</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Tensorflow</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Aws</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Nlp</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Spark</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ai</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>R</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Keras</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cnn</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Flask</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Pandas</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rnn</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Hadoop</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Kubernetes</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Azure</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Mysql</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Spacy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Angularjs</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Nodejs</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Javascript</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Jquery</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Scikit-learn</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Mongodb</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Svm</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Scipy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Numpy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Jira</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Lstm</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           index  freq\n",
              "2         Python    25\n",
              "13    Tensorflow     7\n",
              "7            Aws     7\n",
              "5            Nlp     6\n",
              "9          Spark     6\n",
              "4             Ai     5\n",
              "6              R     5\n",
              "3          Keras     3\n",
              "0            Cnn     2\n",
              "19         Flask     2\n",
              "17        Pandas     2\n",
              "1            Rnn     2\n",
              "10        Hadoop     2\n",
              "11    Kubernetes     2\n",
              "8          Azure     2\n",
              "20         Mysql     2\n",
              "26         Spacy     1\n",
              "25     Angularjs     1\n",
              "24        Nodejs     1\n",
              "22    Javascript     1\n",
              "23        Jquery     1\n",
              "14  Scikit-learn     1\n",
              "21       Mongodb     1\n",
              "18           Svm     1\n",
              "16         Scipy     1\n",
              "15         Numpy     1\n",
              "12          Jira     1\n",
              "27          Lstm     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnIySEyD894x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv-CMDmqjCcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLUdfgBujCnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm9vGcCCjCvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX8SswQjjC4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixR85VSGg409",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-F5Uh4Gg5CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecTOjuWBJChU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}